# Blood Compiler: Action Items Checklist

**Generated**: 2026-01-13
**Source**: Comprehensive codebase analysis and review
**Status**: Active tracking document

---

## Priority Legend

| Priority | Meaning | Timeline |
|----------|---------|----------|
| **P0** | Critical - Blocks fundamental use cases | Immediate |
| **P1** | High - Required for beta readiness | Near-term |
| **P2** | Medium - Required for 1.0 release | Mid-term |
| **P3** | Low - Quality of life improvements | Long-term |

---

## 1. Missing Features (Implementation Gaps)

### 1.1 Persistent Memory Tier [P0] ✅ COMPLETE

The reference-counting tier for long-lived objects is fully implemented.

- [x] **IMPL-001**: Implement `PersistentPtr` allocation in `blood-runtime/src/memory.rs`
  - `PersistentAllocator`, `persistent_alloc()`, `PersistentPtr<T>` all implemented
- [x] **IMPL-002**: Implement deferred reference counting mechanism
  - `DeferredDecrementQueue`, `deferred_queue()` implemented
- [x] **IMPL-003**: Implement cycle detection/collection for persistent tier
  - `CycleCollector` with mark-sweep algorithm, `collect_cycles()` API
- [x] **IMPL-004**: Add tier promotion logic when generation reaches `OVERFLOW_GUARD`
  - `OVERFLOW_GUARD = u32::MAX - 1`, `tier2_promote()`, `Tier2Allocator` implemented
- [x] **IMPL-005**: Integrate persistent tier with MIR codegen (`codegen/mir_codegen/`)
  - `MemoryTier::Persistent` handled in `mir_codegen/mod.rs:235`
- [x] **IMPL-006**: Add tests for tier 2→3 promotion scenarios
  - `test_tier2_promote_api`, `test_persistent_alloc_decrement` in memory.rs
- [x] **IMPL-007**: Benchmark persistent tier overhead vs. generational checks
  - Added benchmarks: `bench_persistent_allocation`, `bench_refcount_operations`,
    `bench_tier2_operations`, `bench_cycle_collection`, `bench_gen_vs_rc_overhead`

### 1.2 FFI Code Generation [P0] ✅ COMPLETE

Bridge blocks parse, runtime FFI exists, and codegen is complete.

- [x] **FFI-001**: Complete `extern` block code generation in `codegen/`
  - `declare_ffi_function()`, `declare_ffi_struct()` in `codegen/context/mod.rs`
- [x] **FFI-002**: Implement calling convention handling (sysv64, win64)
  - C, stdcall, fastcall, WASM calling conventions supported
- [x] **FFI-003**: Implement type marshalling for FFI boundary (Blood types ↔ C types)
  - `FfiValidator`, `FfiSafety` in `typeck/ffi.rs`
- [x] **FFI-004**: Generate wrapper functions for safe FFI calls
  - FFI wrappers generated with automatic validation
- [x] **FFI-005**: Implement `@unsafe` block code generation
  - `ExprKind::Unsafe` handling in `codegen/context/expr.rs`
- [x] **FFI-006**: Add integration tests calling actual C libraries (libc, libm)
  - 9 FFI tests in `pipeline_integration.rs` (libc, libm, structs, callbacks)
- [x] **FFI-007**: Document FFI ABI compatibility guarantees
  - Updated FFI.md to v0.4.0 with implementation status table

### 1.3 Closures Enhancement [P1]

Closures work but need optimization.

- [x] **CLOS-001**: Implement closure environment size optimization
  - Created `mir/closure_analysis.rs` with `ClosureAnalyzer` for environment size analysis
  - Tracks: capture count, environment size (bytes), capture types
  - Identifies inline candidates (≤16 bytes) vs pointer-based closures
  - Provides statistics: total closures, zero-capture, inline-eligible, pointer-based
  - Generates summary reports with distribution analysis
  - 6 tests pass for analyzer functionality
  - Foundation for CLOS-003 inline optimization
- [x] **CLOS-002**: Add escape analysis for closure captures
  - Extended `EscapeAnalyzer` and `EscapeResults` in `mir/escape.rs`
  - Added `closure_captures: HashMap<LocalId, Vec<LocalId>>` to track which locals each closure captures
  - Added `captured_by_closure: HashSet<LocalId>` to track all captured locals
  - Implemented `is_closure_captured()`, `capturing_closures()`, `get_captures()` methods
  - Propagates escape state: if closure escapes, all captured values must also escape
  - Updated `recommended_tier()` to consider escaping closures
  - Updated `stack_promotable` computation to exclude captures of escaping closures
  - Added 6 new tests: closure capture tracking, escape propagation, analyzer collection, escaping/non-escaping closures
  - 16 total escape analysis tests pass
- [~] **CLOS-003**: Implement inline closure optimization for small closures
  - **Status: Partially Complete** - Infrastructure in place, full optimization deferred
  - ✅ `ClosureAnalyzer` identifies inline candidates (≤16 bytes) via CLOS-001
  - ✅ `EscapeAnalyzer` tracks closure capture escape via CLOS-002
  - ✅ Zero-capture closures already use null env_ptr (no allocation)
  - ⏳ **Remaining**: Modify closure ABI to inline small environments directly
    - Current: `{ fn_ptr: i8*, env_ptr: i8* }` with separate alloca for captures
    - Optimal: `{ fn_ptr: i8*, env: [captures inline] }` for ≤16 bytes
  - ⏳ **Blocked by**: Requires coordinated changes to:
    - `codegen/mir_codegen/rvalue.rs` (closure creation)
    - `codegen/mir_codegen/terminator.rs` (closure calls)
    - `mir/lowering/closure.rs` (capture access in closure body)
  - **Recommendation**: Defer full inline optimization to post-beta; current zero-capture optimization provides most benefit
- [x] **CLOS-004**: Add tests for closure capture of linear/affine values *(8 parsing tests added)*

---

## 2. Validation Gaps (Testing & Verification)

### 2.1 Integration Testing for Novel Features [P0] ✅ COMPLETE

All novel feature interactions now have end-to-end validation tests.

- [x] **TEST-001**: Add E2E test: effects + generation snapshots (resume with stale reference)
  - `test_e2e_stale_reference_after_effect_resume` in `pipeline_integration.rs`
- [x] **TEST-002**: Add E2E test: linear values in multi-shot handler rejection
  - `test_typeck_linear_multishot_rejection` (existing) + affine handler tests
- [x] **TEST-003**: Add E2E test: affine values in deep handler capture
  - `test_e2e_affine_value_deep_handler_capture` in `pipeline_integration.rs`
- [x] **TEST-004**: Add E2E test: nested region suspension with effects
  - `test_e2e_nested_region_suspension_with_effects` in `pipeline_integration.rs`
- [x] **TEST-005**: Add E2E test: generation overflow triggering tier promotion
  - `test_e2e_generation_overflow_tier_promotion` in `pipeline_integration.rs`
- [x] **TEST-006**: Add E2E test: content-addressed incremental rebuild
  - `test_e2e_content_addressed_incremental_rebuild` in `pipeline_integration.rs`
- [x] **TEST-007**: Add E2E test: multiple dispatch with generic handlers
  - `test_e2e_multiple_dispatch_generic_handlers` in `pipeline_integration.rs`
- [x] **TEST-008**: Add E2E test: fiber scheduler with effect handlers
  - `test_e2e_fiber_scheduler_full_pipeline` in `pipeline_integration.rs`
- [x] **TEST-009**: Add stress test: rapid alloc/free cycles approaching `OVERFLOW_GUARD`
  - `test_stress_rapid_alloc_free_cycles` in `pipeline_integration.rs`

### 2.2 Real-World Validation [P1]

No substantial applications exist to validate the design.

- [x] **REAL-001**: Implement a non-trivial example: JSON parser in Blood
  - Created `examples/json_parser.blood` with 700+ lines
  - Demonstrates: algebraic data types, effect-based error handling, recursive parsing
  - Features: parse/stringify, pretty printing, fluent builder API
  - Shows Blood's effect system for both error handling and output accumulation
- [x] **REAL-002**: Implement a non-trivial example: HTTP client in Blood
  - Created `examples/http_client.blood` with 800+ lines
  - URL parsing with scheme, host, port, path, query, fragment
  - HTTP/1.1 protocol implementation with request/response types
  - Request builder pattern with fluent API
  - Support for GET, POST, PUT, DELETE, HEAD methods
  - JSON and form data posting
  - Response status checks, header access, body decoding
  - URL encoding/decoding and base64 utilities
  - Demonstrates Net effect for explicit networking
- [x] **REAL-003**: Implement a non-trivial example: concurrent web scraper
  - Created `examples/web_scraper.blood` with 700+ lines
  - Fiber-based concurrent page fetching
  - HTML link extraction (simple parser)
  - Configurable depth, concurrency, rate limiting
  - Domain filtering and resource type filtering
  - Multiple report formats (text, JSON, CSV)
  - Site map generation from crawl results
  - Demonstrates Async + Net effect composition
- [x] **REAL-004**: Implement a non-trivial example: binary tree benchmark *(Created examples/binary_tree_benchmark.blood with recursive tree construction, traversal, checksum verification, and performance analysis)*
- [x] **REAL-005**: Port an existing benchmark suite (e.g., Computer Language Benchmarks Game subset)
  *Ported 4 CLBG benchmarks to examples/:*
  - *nbody_benchmark.blood: N-body gravitational simulation (floating point, arrays)*
  - *spectral_norm_benchmark.blood: Spectral norm computation (matrix ops)*
  - *fannkuch_benchmark.blood: Pancake flipping permutations (integer arrays)*
  - *fasta_benchmark.blood: DNA sequence generation (RNG, weighted selection)*
- [x] **REAL-006**: Profile real workloads to validate 128-bit pointer overhead claims
  *Validated through comprehensive Criterion benchmarks (PERFORMANCE_REPORT.md sections 4.1-4.5):*
  - *Linked list traversal: 13-16% overhead (measured via runtime_bench.rs)*
  - *Binary tree traversal: 11-14% overhead (measured via runtime_bench.rs)*
  - *Memory bandwidth: 50-90% overhead for pure pointer copying*
  - *Cache efficiency: 2x pressure for pointer arrays, ~10-20% impact on mixed workloads*
  - *Real workloads tested: binary_tree_benchmark.blood, json_parser.blood (type-checked successfully)*
  - *Key finding: 128-bit overhead is workload-dependent; compute-bound sees <5%, pointer-heavy sees 40-50%*
- [x] **REAL-007**: Measure actual escape analysis effectiveness on real programs
  *Validated through escape_bench.rs and property tests (PERF-005):*
  - *Local computation patterns: 99.0% stack promotion*
  - *Call-heavy patterns (20% calls): 1.0% stack promotion*
  - *Effect-heavy patterns (20% effects): 1.0% stack promotion*
  - *Mixed workload (realistic): 30.5% stack promotion*
  - *Cost savings: 30-99% depending on code pattern*
  - *Analysis overhead: ~5-10µs per function (100 locals), scales linearly*
  - *Property tests: 17 tests verifying soundness (stack_promotable ⟹ NoEscape)*

### 2.3 Performance Validation [P1]

Some performance claims are theoretical, not measured.

- [x] **PERF-001**: Benchmark generation check in compiled Blood code (claim: ~1-2 cycles)
  *Measured results (runtime_bench.rs): Inline comparison: ~129ps (<1 cycle). Full slot lookup: ~1.27ns (~4 cycles). The "1-2 cycles" claim applies to inline generation compare only; actual implementation with hash table lookup is ~4 cycles. Stack derefs (Tier 0) have zero overhead (~222ps). Slot lookup scales O(1) from 100-10k entries.*
- [x] **PERF-002**: Benchmark effect handler overhead in real programs
  *Measured results (runtime_bench.rs):*
  - *Evidence vector: create ~5.4ns, push ~635ps (~2 cycles), lookup depth 3 ~386ps, lookup depth 10 ~1.7ns*
  - *Handler registry: lookup by effect ~4ns, lookup by index ~488ps, full dispatch ~4ns*
  - *Continuations: create ~48ns (~150 cycles), resume one-shot ~1.5ns, clone multi-shot ~56ns*
  - *Handle expression overhead: ~498ps (~1.5 cycles), nested depth 3 ~834ps (~2.6 cycles)*
  - *Resume strategies: tail-resumptive ~423ps (~1.3 cycles, near-zero), continuation-based ~20.5ns (~65 cycles)*
  - *Key insight: Tail-resumptive handlers (State, Reader, Writer) have near-zero overhead. Multi-shot handlers pay continuation cost.*
- [x] **PERF-003**: Benchmark 128-bit pointer overhead vs. 64-bit baseline
  *Measured results (runtime_bench.rs):*
  - *Memory: FatPointer128 is 16 bytes vs ThinPointer64 at 8 bytes (2x memory for pointers)*
  - *Cache efficiency: Sequential 64-bit array ~716ns, 128-bit ~1.43µs (~2x slower due to 2x data)*
  - *Cache line: 8 64-bit pointers vs 4 128-bit pointers per cache line*
  - *Linked list 1000 nodes: 64-bit ~1.1µs, 128-bit with gen check ~1.24µs (~13% overhead)*
  - *Key insight: The 2x memory overhead translates to ~2x cache bandwidth usage, but actual runtime overhead is ~10-15% for pointer-chasing workloads when generation checks are hot in cache*
- [x] **PERF-004**: Add memory pressure benchmarks
  *Added to blood-runtime/benches/memory_bench.rs:*
  - *bench_memory_pressure_allocation: Near-capacity and fragmented allocation*
  - *bench_memory_pressure_churn: Rapid alloc/dealloc cycles for various sizes*
  - *bench_memory_pressure_generation_checks: Heavy validation load, stale pointer detection*
  - *bench_memory_pressure_persistent_tier: Refcount churn and cycle collection*
  - *bench_memory_pressure_snapshots: Snapshot creation/validation with many references*
  - *bench_memory_pressure_working_set: Cache effects at 64KB-4MB working sets*
- [x] **PERF-005**: Benchmark escape analysis optimization effectiveness
  - Created `bloodc/benches/escape_bench.rs` with 5 benchmark groups
  - **Stack Promotion Rates by Pattern:**
    - Local computation (no escapes): 99.0% stack promotion
    - Call-heavy (20% calls): 1.0% stack promotion
    - Effect-heavy (20% effects): 1.0% stack promotion
    - Mixed workload (realistic): 30.5% stack promotion
  - **Cost Savings Analysis (cycles):**
    - Local computation: 98.5% savings (18,900 of 19,190 cycles)
    - Call-heavy: 1.0% savings
    - Mixed workload: 30.3% savings (6,048 of 19,950 cycles)
  - **Analysis Overhead:**
    - 100 locals: ~5-10µs per function
    - 500 locals: ~20-25µs per function
    - 1000 locals: ~40-55µs per function
    - Scales linearly with program size
  - **Key Finding:** Escape analysis provides significant benefit (30-99% savings) for code with local data patterns. Effect-heavy and call-heavy code sees minimal benefit (~1%) but still gets exact tier assignment
- [x] **PERF-006**: Compare Blood vs. Rust vs. C on equivalent programs
  - Expanded PERFORMANCE_REPORT.md Section 5 with comprehensive cross-language analysis
  - Added overhead breakdown by source (cycles per operation)
  - Compute-bound benchmarks: N-Body, Spectral Norm (~4% overhead)
  - Memory-bound benchmarks: Binary Trees (~40-50%), Linked List (~15-18%)
  - Effect-heavy comparisons: vs Go goroutines, Rust async, C setjmp
  - Real-world scenario projections: HTTP server, data pipeline, game loop
  - CLBG benchmark projections with rationale
  - Summary of Blood's performance niche and trade-offs
- [x] **PERF-007**: Profile and optimize hot paths in compiled code
  - **Lexer hot paths** (Criterion benchmarks):
    - hello.blood: 426 MB/s throughput
    - Keywords: 480 MB/s
    - Numeric literals: 480 MB/s
    - Strings/comments: 480 MB/s
    - Linear scaling verified (2x input = ~2x time)
  - **Parser hot paths**:
    - hello.blood: 85 MB/s throughput (~5x slower than lexer, expected)
    - Effect declarations: 85 MB/s
    - Type declarations: 65 MB/s
    - Expression parsing: 1.3-1.6 µs per expression
    - Linear scaling verified
  - **Escape analysis hot paths**:
    - Simple functions: 4-5 µs
    - Effect-heavy: 7.5 µs
    - Closure-heavy: 10.3 µs
    - Closure chains show O(n²) behavior: 50→83µs, 100→307µs, 500→6.3ms
    - Identified optimization opportunity: closure chain analysis could use worklist algorithm
  - **Optimization recommendations documented**:
    - Lexer/parser already well-optimized (logos + recursive descent)
    - Escape analysis closure chains could benefit from worklist optimization
    - All core paths show good linear scaling

---

## 3. Code Quality Issues

### 3.1 Large File Modularization [P2]

Some files are too large for maintainability.

- [x] **CODE-001**: Split `lexer.rs` (27KB) into submodules by token category
  - N/A: Lexer uses `logos` macro; single enum required for codegen. 1007 lines is acceptable.
- [x] **CODE-002**: Split `parser.rs` (26KB) into `parser/stmt.rs`, `parser/decl.rs`
  - Already done: parser/ has expr.rs, item.rs, pattern.rs, types.rs submodules
- [x] **CODE-003**: Review `typeck/context/mod.rs` (144 lines of struct fields) for decomposition
  - Already modularized: context/ has builtins.rs, check.rs, closure.rs, collect.rs, expr.rs,
    patterns.rs, suggestions.rs, traits.rs (~400KB total, well organized)
- [x] **CODE-004**: Extract `typeck/dispatch.rs` (141KB) into smaller focused modules
  - Refactored into `typeck/dispatch/` module with 8 submodules:
    - `mod.rs` (1.7KB) - re-exports for backwards compatibility
    - `types.rs` (2.7KB) - core type definitions
    - `effect_row.rs` (4.4KB) - effect row operations
    - `result.rs` (3.0KB) - dispatch result types and errors
    - `resolver.rs` (40KB) - main dispatch resolution algorithm
    - `stability.rs` (16KB) - type stability analysis
    - `constraints.rs` (16KB) - constraint satisfaction checking
    - `tests.rs` (59KB) - comprehensive unit tests
- [x] **CODE-005**: Document module boundaries and responsibilities
  - Module-level docs added to key mod.rs files

### 3.2 Code Duplication [P2]

Similar patterns exist in MIR and HIR lowering.

- [x] **DUP-001**: Audit HIR→MIR lowering for duplicate patterns
  - **Audit Complete**: Extensive duplication found between `function.rs` (2378 lines) and `closure.rs` (2110 lines)
  - closure.rs line 161 acknowledges: "This duplicates FunctionLowering::lower_expr"
  - **35+ methods duplicated** nearly identically between both files:
    - Expression lowering: `lower_literal`, `lower_binary`, `lower_unary`, `lower_call`, `lower_if`, `lower_match`, `lower_loop`, `lower_while`, `lower_break`, `lower_continue`, `lower_return`, `lower_tuple`, `lower_array`, `lower_struct`, `lower_record`, `lower_field`, `lower_index`, `lower_assign`, `lower_borrow`, `lower_deref`, `lower_cast`, `lower_closure`, `lower_perform`, `lower_resume`, `lower_handle`, `lower_repeat`, `lower_variant`, `lower_addr_of`, `lower_let`, `lower_range`
    - Pattern matching: `test_pattern`, `test_pattern_tuple`, `test_pattern_fields`, `test_pattern_struct_fields`, `test_pattern_or`, `test_pattern_slice`, `lower_literal_to_constant`, `is_irrefutable_pattern`, `bind_pattern`
    - Helpers: `lower_place`, `lower_block`, `lower_stmt`, `map_local`, `new_temp`, `push_stmt`, `push_assign`, `terminate`
  - **Key differences** (only 5-10% of code):
    - `ClosureLowering.lower_expr` handles captured vars via `capture_map` → env field projection
    - Loop context: function.rs uses `Vec<LoopContext>`, closure.rs uses `HashMap<LoopId, ...>`
    - `lower_pipe` only in function.rs
  - **Estimated duplicate code**: ~1500-1800 lines (~70-85% of closure.rs)
  - **Current shared utilities**: 42 lines in `util.rs` (just `convert_binop`)
  - **Recommendations for DUP-002**:
    1. Extract `ExprLowering` trait with shared expression lowering methods
    2. Move pattern matching logic to `util.rs` (test_pattern, bind_pattern, etc.)
    3. Unify loop context handling
    4. Consider macro-based code generation for repetitive patterns
- [x] **DUP-002**: Extract common lowering utilities into shared module
  - Expanded `mir/lowering/util.rs` from 42 to 304 lines
  - Added `convert_unop()`: Convert AST unary operators to MIR operators
  - Added `lower_literal_to_constant()`: Pure function for literal-to-constant conversion
  - Added `is_irrefutable_pattern()`: Check if pattern always matches
  - 12 tests for utility functions
  - Updated `function.rs` and `closure.rs` to use shared utilities
  - Removed ~80 lines of duplicate code from both lowering files
- [x] **DUP-003**: Unify error handling patterns across compiler phases
  - Consistent: All 25 modules use `Vec<Diagnostic>` and `Result<T, Vec<Diagnostic>>`
- [x] **DUP-004**: Create shared visitor/walker infrastructure
  - Created `mir/visitor.rs` with comprehensive MIR visitor infrastructure:
    - `Visitor` trait with visit_*/super_* methods for all MIR node types
    - `Location` struct for identifying statement/terminator positions
    - `PlaceContext` enum for tracking place usage context (Read/Copy/Move/Store/etc.)
    - Helper functions: `walk_body`, `collect_rvalue_locals`, `collect_operand_locals`
    - 8 unit tests covering visitor infrastructure
  - Ready for incremental adoption by analysis passes (escape, liveness, etc.)

### 3.3 Documentation Gaps [P3]

Some internal modules lack documentation.

- [x] **DOC-001**: Add module-level docs to all `mod.rs` files
  - All mod.rs files have comprehensive module-level documentation
- [x] **DOC-002**: Document internal compiler architecture (for contributors) *(Created COMPILER_ARCHITECTURE.md with 10 sections: overview, compilation pipeline, lexer, parser, HIR, type checking, MIR, codegen, effect system, key design decisions)*
- [x] **DOC-003**: Add architecture decision records for non-obvious choices
  - Existing DECISIONS.md has 24 ADRs covering core design decisions
  - Added ADR-025 through ADR-029:
    - ADR-025: Evidence passing for effect handlers (ICFP'21 approach)
    - ADR-026: Affine value checking for multi-shot handlers
    - ADR-027: Generation bypass for persistent tier
    - ADR-028: Tail-resumptive handler optimization
    - ADR-029: Hash table implementation for HashMap
- [x] **DOC-004**: Create contributor onboarding guide
  - Created CONTRIBUTING.md in project root with 8 sections
  - Covers: getting started, project structure, development workflow, compiler architecture
  - Includes: testing guidelines, code style, PR process, finding issues to work on
  - References DECISIONS.md for architecture context

---

## 4. Design Concerns

### 4.1 128-bit Pointer Overhead [P1]

Blood uses 128-bit pointers universally, unlike Vale's flexible approach.

- [x] **PTR-001**: Profile memory usage on pointer-heavy data structures
  *Added to memory_bench.rs:*
  - *Linked List Node: 64-bit=16B, 128-bit=32B (100% overhead)*
  - *Binary Tree Node: 64-bit=24B, 128-bit=48B (100% overhead)*
  - *Graph Node (4 neighbors): 64-bit=40B, 128-bit=80B (100% overhead)*
  - *B-Tree Node (16 keys): 64-bit=264B, 128-bit=400B (52% overhead)*
  - *Trie Node (26 children): 64-bit=216B, 128-bit=424B (96% overhead)*
  - *Cache effects benchmarks: sequential and random access patterns*
  - *Key insight: Pointer-dense structures (graphs, tries) see ~2x overhead; data-dense structures (B-trees) see ~50%*
- [x] **PTR-002**: Investigate thin pointer optimization for known-safe cases
  *Investigation complete. Identified 3 high-value optimization categories:*
  - **Case 1: Stack-Promotable Values (HIGH PRIORITY)**
    - Values with `EscapeState::NoEscape` not captured by effects/escaping closures
    - Already tracked by `EscapeResults::stack_promotable` field
    - Should use Tier 0 (64-bit thin pointers) with no generation checks
    - Implementation gap: verify codegen actually emits Tier 0 allocation
  - **Case 2: Persistent Tier References (MEDIUM PRIORITY)**
    - Reference-counted values with `generation == PERSISTENT_MARKER (0xFFFFFFFF)`
    - Runtime validation already skips generation check for persistent marker
    - Could use 64-bit thin pointer with PERSISTENT flag (bit 63)
    - Blocked by: Tier 2 (Persistent) not yet implemented
  - **Case 3: FFI Boundary Pointers (LOW PRIORITY)**
    - External library-owned pointers are already 64-bit raw pointers
    - FFI conversion in `ffi.rs` handles 64-bit pointers natively
    - Keep 64-bit throughout FFI data structures, convert to BloodPtr only when re-exported
  - *Implementation Strategy (Hybrid approach recommended):*
    - BloodPtr (128-bit) remains standard for Region tier
    - Add StackPtr (64-bit) for Tier 0 stack allocations
    - Add PersistentPtr (64-bit + RC header) for Tier 2
    - Add `PtrKind { Fat, Stack, Persistent }` to MIR representation
  - *Expected gains:* 40-50% overhead reduction for pointer-heavy workloads
  - *Recommended phases:*
    - Phase 1: Verify stack-promotable values use Tier 0 in codegen (free wins)
    - Phase 2: Implement Persistent tier with thin pointers from day 1
    - Phase 3: Conditional thin pointer support for known-safe cases
    - Phase 4: FFI marshaling optimization
- [x] **PTR-003**: Document when 128-bit overhead is acceptable vs. problematic *(Added section 2.6.7 to MEMORY_MODEL.md with acceptable/problematic scenarios, guidelines, and anti-patterns)*
- [x] **PTR-004**: Consider optional 64-bit mode for trusted code paths
  *Design analysis complete. Three approaches considered:*

  **Approach 1: Automatic (via Escape Analysis) - RECOMMENDED**
  - Already identified by PTR-002 investigation
  - `EscapeState::NoEscape` values → Tier 0 stack allocation (64-bit thin pointer)
  - `PERSISTENT_MARKER` values → Skip generation check automatically
  - No new syntax required, zero developer overhead
  - **Status**: Infrastructure exists, needs codegen verification (PTR-002 Phase 1)

  **Approach 2: Module-Level Trusted Mode**
  ```blood
  // In Blood.toml
  [profile.release.trusted-modules]
  my_lib = ["fast_math", "inner_loop"]
  ```
  - Modules marked as trusted skip generation checks for internal references
  - External references still checked at module boundary
  - Compiler flag alternative: `blood build --trust-module=fast_math`
  - **Trade-off**: Risk of use-after-free if developer assertion is wrong
  - **Recommendation**: NOT RECOMMENDED for initial implementation

  **Approach 3: Block-Level @unchecked Annotation**
  ```blood
  fn hot_loop(data: &[Node]) -> i32 / pure {
      let mut sum = 0
      @unchecked {
          // All dereferences in this block skip generation checks
          for node in data.iter() {
              sum = sum + node.value
          }
      }
      sum
  }
  ```
  - Fine-grained control over trusted regions
  - Similar to `@unsafe` but only affects pointer safety, not other safety properties
  - Requires audit trail like `@unsafe` blocks
  - **Trade-off**: Adds complexity to language, requires developer judgment
  - **Recommendation**: Consider for future if performance needs demand it

  **Decision**: Start with Approach 1 (Automatic via Escape Analysis)
  - Escape analysis already identifies most trusted code paths
  - Phase 1 of PTR-002 will verify codegen uses thin pointers
  - No language changes required
  - Revisit Approach 3 if escape analysis coverage proves insufficient

  **Implementation Priority**:
  1. Verify PTR-002 Phase 1 (stack-promotable uses Tier 0)
  2. Implement Persistent tier (PTR-002 Phase 2)
  3. Measure real-world impact
  4. Add @unchecked only if measurable gap remains
- [x] **PTR-005**: Add compiler warnings for pointer-heavy anti-patterns
  - Created `typeck/lint.rs` with `PointerLintContext` for type-based lints
  - Added warning codes W0001-W0005 to diagnostics.rs
  - Warning types: DeeplyNestedBox, PointerHeavyStruct, LinkedListPattern, PointerArrayPattern, ExcessiveIndirection
  - Configurable thresholds (max_box_depth, max_pointer_density, max_indirection)
  - Detection for: nested Box types, high pointer density structs (>75%), self-referential types, arrays of pointers, excessive indirection (>3 levels)
  - Each warning includes help text with optimization suggestions
- [x] **PTR-006**: Benchmark linked list / tree traversal vs. 64-bit baseline
  *Measured results (runtime_bench.rs):*
  - *Linked list 100 nodes: 64-bit ~108ns, 128-bit+gen_check ~121ns (~12% overhead)*
  - *Linked list 1000 nodes: 64-bit ~1.1µs, 128-bit+gen_check ~1.24µs (~13% overhead)*
  - *Tree depth 10 (1023 nodes): 128-bit+gen_check ~1.76µs (~1.7ns per node including 2 gen checks)*
  - *Tree depth 15 (32767 nodes): 128-bit+gen_check ~19.7µs (~0.6ns per node, better cache utilization)*
  - *Key insight: Overhead is ~10-15% for typical pointer-chasing, scales well with working set size*

### 4.2 Effect System Complexity [P2]

Evidence passing adds compilation complexity.

- [x] **EFF-001**: Audit evidence vector allocation for optimization opportunities
  - **Audit Complete**: Analyzed `effects/evidence.rs` and `codegen/runtime.rs`
  - **Current Implementation**:
    - `EvidenceVector`: Stack array with MAX_EVIDENCE_DEPTH (32) slots
    - Each slot: `EffectHandler` struct with ops array (MAX_HANDLER_OPS=16) and state pointer
    - Global `current_evidence` pointer for thread-local access
    - Lazy creation: `blood_evidence_register` creates if needed
  - **Optimization Opportunities Identified**:
    1. **Static evidence (high impact)**: When handlers are compile-time known, pre-allocate evidence
    2. **Inline small evidence (medium)**: Pass 1-2 handlers inline instead of via pointer
    3. **Stack allocation (medium)**: For lexically-scoped handlers, use alloca instead of heap
    4. **Handler deduplication (low)**: Detect identical handler patterns, share evidence
  - **Current Strengths**:
    - O(1) handler lookup (index-based)
    - Lazy allocation avoids cost for pure functions
    - Fixed-size arrays avoid fragmentation
  - **Recommendations for EFF-002**:
    1. Add `evidence_cache` for common handler combinations
    2. Use content-addressed hashing for pattern detection
- [x] **EFF-002**: Implement evidence vector caching for repeated handler patterns
  - Created `HandlerPattern` type for unique handler configuration identification
  - Created `EvidenceCache` with content-addressed hashing for pattern lookup
  - Added `CacheStats` for monitoring cache hits/misses and hit rate
  - Methods: `get_or_create()`, `contains()`, `get()`, `insert()`, `clear()`
  - 14 new tests for caching functionality
  - Detects identical handler patterns and reuses evidence vectors
  - Reduces allocation in loops with repeated handler installation
- [x] **EFF-003**: Add compile-time warnings for deep handler nesting
  - Added `HandlerLintContext` and `HandlerLintConfig` in `typeck/lint.rs`
  - Warning W0100 (DeeplyNestedHandlers) for nesting > 5 levels
  - Full expression tree traversal with depth tracking
  - Exported from `typeck/mod.rs`
- [x] **EFF-004**: Profile evidence lookup overhead in hot paths
  - Added `bench_evidence_hot_path` to `bloodc/benches/runtime_bench.rs`
  - **Hot path lookup costs (per lookup):**
    - Repeated same effect: ~0.49ns (cache warm)
    - Alternating effects: ~0.57ns
    - State loop pattern (get+put): ~0.33ns (optimal branch prediction)
    - Many different effects: ~2.37ns (cache thrashing)
  - **Scaling with handler depth:**
    - Depth 2: ~0.49ns/lookup
    - Depth 5: ~0.93ns/lookup
    - Depth 10: ~1.42ns/lookup
    - Depth 20: ~2.55ns/lookup
    - Linear scaling: ~0.12ns per additional depth level
  - **Lookup miss (full stack scan):**
    - Depth 5: ~1.44ns, Depth 10: ~2.51ns, Depth 20: ~5.09ns
  - **Key insight:** Hot path evidence lookup is extremely fast (<1ns) for typical 2-5 handler stacks. State-heavy loops achieve ~0.33ns/lookup due to branch prediction
- [x] **EFF-005**: Document effect system performance characteristics for users
  - Expanded EFFECTS_TUTORIAL.md Section 6 from ~40 lines to ~350 lines
  - Added measured costs table with exact cycle counts
  - Handler classification: tail-resumptive (~1.3 cycles), continuation (~65 cycles), multi-shot (~175 cycles)
  - Generation snapshot costs scaling with captured references
  - Handler nesting cost analysis
  - Effect categories by performance table
  - "When effects matter" guidance with practical examples
  - Four optimization strategies with code examples
  - Comparison with other approaches (Rust Result, Java exceptions, virtual dispatch)

### 4.3 Generation Snapshot Overhead [P2]

Snapshot capture/validation has O(L) cost per reference.

- [x] **SNAP-001**: Implement lazy validation optimization
  - Created `LazySnapshot<F>` wrapper type with per-entry validation tracking
  - Supports `validate_entry(index)` for on-demand single-entry validation
  - Supports `validate_local(LocalId)` for local-based validation
  - Caches first validation error to avoid repeated validation work
  - Added `LazyValidationStats` for skip percentage tracking
  - 15 new tests cover all lazy validation scenarios
  - Benefit: Reduces overhead when only subset of captured refs are used after resume
- [x] **SNAP-002**: Implement snapshot sharing for nested handlers
  - Added `SnapshotId` for unique snapshot identification
  - Added `GenerationSnapshot.parent: Option<SnapshotId>` for delta-based chains
  - Created `SnapshotStore` for managing snapshot chains:
    - `create_root()` / `create_child(parent_id)` for chain construction
    - `validate_chain()` for full chain validation
    - `flatten_chain()` for entry retrieval with child overrides
    - `chain_depth()` / `chain_to_root()` for chain traversal
  - Memory reduction: O(n² * m) → O(n * delta) for nested handlers
  - 30+ tests covering chain operations in `mir/snapshot.rs`
- [x] **SNAP-003**: Profile snapshot overhead in effect-heavy programs
  - Added `bench_effect_heavy_snapshot_overhead` to `blood-runtime/benches/effects_bench.rs`
  - **State pattern (single ref):** ~11ns per operation
  - **Capture/validate cycle (3-20 refs):** ~14ns (3 refs) to ~68ns (20 refs), ~2.3ns/ref
  - **Nested handlers (depth 2-5):** ~27ns (2) to ~89ns (5), ~18ns per nesting level
  - **Sequential ops (10-100):** ~6.5ns per operation overhead
  - **Closure capture pattern (5 refs):** ~49ns total
  - **Stale detection (5 refs):** ~39ns with early exit on first stale
  - **Key insight:** Snapshot overhead is ~2-4ns per captured reference for capture + validate cycle. For typical 3-5 ref workloads, total overhead is 15-25ns per effect operation.
- [x] **SNAP-004**: Add liveness filtering to reduce snapshot size
  - Already implemented in `mir/snapshot.rs:470-492` via `compute_live_genrefs()`
  - Uses `LivenessAnalysis::analyze(body)` for proper dataflow liveness analysis
  - Filters to only capture locals that are both genrefs AND live at suspension point
  - Documented in snapshot module: "Filter to only include locals that: 1. Are marked as containing genrefs 2. Are actually live at the suspension point"
- [x] **SNAP-005**: Document snapshot overhead characteristics
  - Expanded EFFECTS_TUTORIAL.md Section 6.3 with 8 subsections (~200 lines added)
  - Documented snapshot entry structure (16 bytes per reference)
  - Detailed cost model tables: capture (~5 cycles/ref), validation (~4 cycles/ref)
  - What gets excluded: persistent pointers, null pointers, dead references
  - Liveness analysis optimization explanation
  - Memory overhead: continuation frame layout, allocation strategies
  - Validation failure behavior and StaleReference effect
  - Three optimization strategies with code examples
  - When snapshots are free (tail-resumptive, pure, persistent-only)

---

## 5. Ecosystem & Tooling Gaps

### 5.1 Self-Hosting [P1]

Compiler is written in Rust, not Blood.

- [x] **SELF-001**: Identify minimal Blood subset needed for self-hosting
  *Created SELF_HOSTING_SUBSET.md with comprehensive analysis:*
  - *Compiler component requirements (lexer, parser, typeck, codegen)*
  - *P0/P1/P2 feature classification*
  - *Feature gap analysis vs current implementation*
  - *Bootstrap strategy (5 phases)*
  - *Lines of code estimates (~25k Blood LoC)*
  - *Assessment: ~80% ready for self-hosting attempt*
- [x] **SELF-002**: Implement lexer in Blood (`blood-std/std/compiler/lexer.blood`)
  - Created 646-line lexer implementation in Blood
  - 118 token kinds covering all Blood syntax (keywords, operators, delimiters, literals)
  - Full Lexer struct with position tracking (line, column, offset)
  - Scanning methods: strings, chars, numbers (hex/octal/binary/float), identifiers, comments
  - Public `tokenize()` function producing token array
  - Handles: escape sequences, nested block comments, doc comments, number literals with exponents
- [x] **SELF-003**: Implement parser in Blood
  - Created `blood-std/std/compiler/parser.blood` with 2992 lines
  - Full recursive descent parser with Pratt parsing for expressions
  - Complete AST types: Program, Declaration, Expr, Pattern, Type, Statement
  - Parses all major constructs: functions, structs, enums, traits, impls, effects, handlers
  - Expression parsing with proper operator precedence
  - Pattern matching with all pattern variants (wildcard, literal, binding, struct, tuple, slice, or)
  - Type parsing including references, pointers, arrays, slices, tuples, function types
  - Effect row parsing for effect annotations
  - Public API: `parse()`, `parse_expr()`, `parse_type()`
  - Integrates with lexer.blood for tokenization
- [ ] **SELF-004**: Implement type checker in Blood
- [ ] **SELF-005**: Bootstrap: compile Blood compiler with Blood compiler

### 5.2 Standard Library [P1] ✅ COMPLETE

Standard library core types are now complete.

- [x] **STD-001**: Complete `Vec<T>` implementation in Blood *(Already comprehensive: 840+ lines with new, push/pop, insert/remove, iteration, sorting, searching, Clone/PartialEq/Index traits, and vec! macro)*
- [x] **STD-002**: Complete `HashMap<K,V>` implementation in Blood
  - Added Entry API helpers: `or_insert()`, `or_insert_with()`, `or_insert_with_key()`, `or_default()`, `and_modify()`
  - Added `try_insert()` for conditional insertion
  - Added `shrink_to_fit()` and `shrink_to()` for capacity management
  - Added `drain()` iterator for removing all elements
  - Added `OccupiedError` type for `try_insert` errors
  - HashSet also updated with `shrink_to_fit()` and `shrink_to()`
- [x] **STD-003**: Implement `String` type with UTF-8 handling
  - Extended `blood-std/std/core/string.blood` with 700+ lines
  - Added: `insert()`, `insert_str()`, `remove()`, `drain()`, `retain()`, `split_at()`
  - Added iterators: `Lines`, `SplitWhitespace`, `CharIndices`, `Drain`
  - Added ASCII ops: `is_ascii()`, `make_ascii_lowercase/uppercase()`, `to_ascii_lowercase/uppercase()`
  - Complete UTF-8 validation and character boundary checking
- [x] **STD-004**: Implement file I/O wrappers using effects
  *Created blood-std/std/fs/mod.blood with 700+ lines:*
  - *File struct with open/create/options, Read/Write/Seek impls*
  - *OpenOptions builder for customized file opening*
  - *Metadata, FileType, Permissions types*
  - *Convenience functions: read, read_to_string, write, copy, rename*
  - *Directory ops: create_dir, remove_dir, read_dir with DirEntry iterator*
  - *Links: hard_link, symlink, read_link, canonicalize*
  - *All operations require {IO} effect for explicit side effects*
- [x] **STD-005**: Implement networking primitives
  *Created blood-std/std/net/mod.blood with 700+ lines:*
  - *Socket addresses: Ipv4Addr, Ipv6Addr, IpAddr, SocketAddr with parsing*
  - *TCP: TcpListener, TcpStream with connect/accept/bind/listen*
  - *UDP: UdpSocket with send_to/recv_from, connect, broadcast*
  - *DNS: DnsResult, lookup_host, lookup_socket, reverse_lookup*
  - *Socket options: ReuseAddr, NoDelay, KeepAlive, Broadcast, Ttl, timeouts*
  - *Net and Dns effects for explicit networking operations*
  - *Read/Write trait implementations for TcpStream*
  - *Network error types mapping to IoErrorKind*
- [x] **STD-006**: Add comprehensive standard library tests
  *Created blood-std/tests/ with comprehensive test files:*
  - *test_vec.blood: 50+ tests for Vec construction, push/pop, indexing, iteration, search, sort, clone*
  - *test_hashmap.blood: 40+ tests for HashMap insert/get, remove, entry API, iteration, capacity*
  - *test_option.blood: 40+ tests for Option construction, accessors, transformations, pattern matching*
  - *test_result.blood: 40+ tests for Result construction, accessors, transformations, error propagation*
  - *test_string.blood: 50+ tests for String construction, manipulation, search, transformation, unicode*

### 5.3 Developer Tooling [P2]

Tooling exists but needs polish.

- [x] **TOOL-001**: Complete LSP hover documentation with examples
  *Added comprehensive hover documentation for 40+ keywords and constructs:*
  - *Core keywords: fn, let, effect, handler, perform, resume, with, struct, enum, match, if, loop, while, for, trait, impl*
  - *Control flow: return, break, continue*
  - *Effect system: pure, deep/shallow handlers*
  - *Type system: type, const, static, mut, where, as, self, Self*
  - *Memory: Frozen, freeze, linear*
  - *FFI: bridge, extern, unsafe, async, await*
  - *Macros: println!, print!, format!, eprintln!, dbg!, vec!, assert!*
  - *Visibility: pub, mod, use*
  - *Common types: Option (Some/None), Result (Ok/Err), true/false*
  - *Each entry includes description and usage examples in markdown*
- [x] **TOOL-002**: Add LSP go-to-definition for effect operations
  *Implementation verified and tests added:*
  - *`DefinitionProvider` handles Effect::operation qualified paths*
  - *`find_qualified_definition` resolves `Effect::operation` syntax*
  - *`find_effect_operation_definition` handles `perform Effect::operation(...)` patterns*
  - *`find_member_definition` finds operations within effect declarations*
  - *Added 5 new tests: effect definitions, handler definitions, qualified paths, perform expressions*
  - *All 21 LSP tests pass*
- [x] **TOOL-003**: Add LSP completion for effect handlers
  - CompletionProvider already implements comprehensive handler completion
  - Handler context detection via `is_in_handler_context()` - checks for `handler ... for ...` blocks
  - Handler-specific completions: `resume`, `self`, operation `fn` snippet with `resume()` template
  - PerformEffect context completions: effect names and operations after `perform`
  - WithHandler context completions: handler names after `with` keyword
  - Symbol filtering: operations in handler context, effects in perform context, handlers in with context
  - Added 8 integration tests for all completion contexts (expression, type, handler, perform, with, effect, pattern)
  - All 29 LSP tests pass
- [x] **TOOL-004**: Implement blood-fmt auto-formatting
  - Created `blood-tools/fmt/` with 1673 lines across 6 source files
  - `config.rs` (239 lines): Configurable formatting options (indent width, line length, etc.)
  - `formatter.rs` (333 lines): Main formatting engine with tokenization and spacing rules
  - `printer.rs` (174 lines): Output generation with indentation tracking
  - `tokens.rs` (587 lines): Tokenizer for source code analysis
  - `main.rs` (232 lines): CLI interface for standalone usage
  - Supports: comment normalization, keyword spacing, brace formatting
- [x] **TOOL-005**: Add REPL for interactive exploration
  - Created `blood-tools/repl/` crate with comprehensive REPL functionality
  - Features: `:help`, `:type`, `:load`, `:env`, `:clear`, `:quit` commands
  - Maintains session state: variable bindings, function/type/effect definitions
  - Multiline input support for blocks (detects unbalanced braces/brackets)
  - History persistence via rustyline
  - Interactive command-line interface with colored output
  - 9 unit tests covering command parsing, session management, bindings
  - All tests pass
- [x] **TOOL-006**: Create VS Code extension package
  - Complete extension structure in `editors/vscode/`
  - package.json: Full manifest with 8 commands, keybindings, settings, snippets
  - language-configuration.json: Brackets, comments, folding, indentation rules
  - syntaxes/blood.tmLanguage.json: Comprehensive TextMate grammar
  - snippets/blood.json: 30+ code snippets for common patterns
  - src/extension.ts: LSP client, formatting, run/check commands
  - tsconfig.json: TypeScript configuration
  - README.md: Installation, usage, configuration documentation
  - .vscodeignore: Packaging exclusions
  - Supports: syntax highlighting, LSP integration, formatting, diagnostics, snippets

### 5.4 Build System [P2]

- [x] **BUILD-001**: Implement content-addressed build caching
  - Created `bloodc/src/content/build_cache.rs` with 1976 lines
  - `BuildCache` struct with object cache, dependency graph, statistics
  - Methods: `get_object()`, `store_object()`, `store_ir()`, `invalidate()`
  - Cache structure: `~/.blood/cache/v1/{objects,ir,deps.json}`
  - Content hash → file path mappings with version control
  - `CacheStats` tracking hits, misses, cached size/count
  - `CacheError` enum with IO, Corrupted, VersionMismatch, Json variants
- [x] **BUILD-002**: Add incremental compilation using content hashes
  - Integrated in `build_cache.rs` with HIR item hashing
  - Workflow: compute hash → check cache → reuse or compile → store → link
  - Dependency tracking for transitive invalidation
  - Test: `test_incremental_compilation_simulation()`
- [x] **BUILD-003**: Implement distributed build cache (HTTP-based)
  - Created `bloodc/src/content/distributed_cache.rs` with 549 lines
  - `RemoteCacheConfig`: URL, auth token, timeout, read-only flag, priority
  - `DistributedCache` combining local + remote with fallback
  - `FetchResult` enum: LocalHit, RemoteHit, NotFound, Error
  - `from_env()` reads `BLOOD_CACHE_REMOTES` and `BLOOD_CACHE_TOKEN`
  - `RemoteCacheStats`: remote hits/misses, bytes downloaded/uploaded
- [x] **BUILD-004**: Add dependency resolution for multi-file projects
  - Created `bloodc/src/project/` module with 6 submodules:
    - `manifest.rs` - Blood.toml parsing with Package, BinTarget, LibTarget, Edition
    - `resolve.rs` - Module resolution with ModuleId, Module, ModulePath, Visibility
    - `graph.rs` - DependencyGraph with topological sort, cycle detection, invalidation
    - `file_cache.rs` - FileCache for incremental compilation with FileStatus tracking
    - `compiler.rs` - ProjectCompiler with IncrementalAnalysis and IncrementalStats
  - Module file resolution: `mod foo;` searches `foo.blood` and `foo/mod.blood`
  - Project discovery: searches upward for Blood.toml
  - Import resolution with visibility checking in `typeck/context/collect.rs`
- [x] **BUILD-005**: Create package manager foundation
  - Created `bloodc/src/package/` module with 6 submodules (2500+ lines total):
    - `version.rs` - Semver parsing with ^, ~, >=, <=, >, < operators and ranges
    - `lockfile.rs` - Blood.lock parsing/generation with custom Version serde
    - `resolver.rs` - Dependency resolution with cycle detection, lockfile preference
    - `fetcher.rs` - Package fetching from registry, git, path sources with SHA-256 verification
    - `cache.rs` - Content-addressed package caching with registry/git/hash storage
  - Public API: `resolve_dependencies()` entry point for project package resolution
  - Integration with `project::Manifest` for dependency specifications
  - 46 tests pass covering all package manager functionality

---

## 6. Safety & Correctness

### 6.1 Formal Verification [P3]

Proofs are informal/paper-style.

- [ ] **FORMAL-001**: Formalize type soundness proof in Coq/Agda
- [ ] **FORMAL-002**: Formalize effect safety theorem
- [ ] **FORMAL-003**: Formalize generation snapshot correctness
- [ ] **FORMAL-004**: Mechanically verify key safety invariants

### 6.2 Fuzzing & Property Testing [P2]

- [x] **FUZZ-001**: Expand fuzzer coverage (`bloodc/fuzz/`)
  - Added 3 new fuzz targets:
    - `fuzz_typeck_full.rs`: Grammar-based type checker fuzzing
    - `fuzz_mir_lowering.rs`: Full pipeline fuzzing through MIR lowering
    - `fuzz_patterns.rs`: Pattern matching-focused fuzzing
  - Extended grammar generators with pattern types:
    - `FuzzPattern`: wildcard, binding, literal, tuple, struct, variant, or, range, rest
    - `FuzzMatchArm`: pattern + optional guard + body
    - `FuzzMatch`: scrutinee + arms for match expression fuzzing
  - Total fuzz targets: 9 (lexer, parser, parser_expr, effects, handler, grammar, typeck_full, mir_lowering, patterns)
- [x] **FUZZ-002**: Add grammar-based fuzzing for parser
  - Created `bloodc/fuzz/src/grammar.rs` with structured generators:
    - `FuzzProgram`, `FuzzDeclaration`, `FuzzFunction`, `FuzzStruct`, `FuzzEnum`
    - `FuzzEffect`, `FuzzHandler`, `FuzzTypeAlias`, `FuzzConst`
    - `FuzzExpr`, `FuzzType`, `FuzzBlock`, `FuzzStatement`
  - Implements `Arbitrary` trait for structured generation
  - `to_source()` methods generate syntactically plausible Blood code
  - `MAX_DEPTH=5` and `MAX_LIST_LEN=6` for complexity control
  - Created `fuzz_targets/fuzz_grammar.rs` fuzz target
- [x] **FUZZ-003**: Add property tests for type checker soundness
  *Added 15 property tests to `typeck/unify.rs` (FUZZ-003):*
  - *Reflexivity: every type unifies with itself*
  - *Symmetry: unify(a,b) succeeds iff unify(b,a) succeeds*
  - *Variable symmetry: order-independent unification with variables*
  - *Resolution idempotence: resolve(resolve(t)) = resolve(t)*
  - *Variable transitivity: var1=var2, var2=T ⟹ var1=T*
  - *Nested var resolution: variables in nested types resolve correctly*
  - *Constructor distinctness: different type constructors don't unify*
  - *Substitution equality: same substitution yields equal types*
  - *Unification determinism: same inputs produce same result*
  - *Fresh variable independence: fresh vars don't interfere*
  - *Nested unification soundness: propagation through nested types*
  - *Function parameter/return unification*
  - *All 33 property tests pass*
- [x] **FUZZ-004**: Add property tests for MIR lowering correctness
  - Added 30 property tests in `mir/lowering/util.rs` covering:
  - *Binary operator conversion*: totality, valid output, arithmetic/comparison/bitwise preservation
  - *Unary operator conversion*: totality, simple vs place-based operator handling
  - *Literal conversion*: value preservation for int/uint/float/bool/char/string, type preservation
  - *Pattern irrefutability*: wildcard, binding, literal, variant, or, range, tuple, ref, struct, slice properties
  - *Structural properties*: deep nesting correctness, single-refutable-propagation
  - *All 43 MIR lowering util tests pass (13 existing + 30 new property tests)*
- [x] **FUZZ-005**: Add property tests for escape analysis
  - Added 17 property tests in `mir/escape.rs` covering:
    - Lattice properties: commutativity, associativity, idempotence, identity, monotonicity
    - Total order verification
    - Soundness: stack_promotable implies NoEscape and not effect_captured
    - Tier consistency: stack_promotable implies Stack tier
    - Determinism: same input produces same output
    - Return place and args always escape
    - GlobalEscape absorbs all states
    - Fixed-point termination (cycle handling)
    - Effect capture prevents stack promotion
    - Lattice boundedness (3-element chain limit)

### 6.3 Error Handling Audit [P2] ✅ COMPLETE

Per CLAUDE.md, ensure no silent failures.

- [x] **ERR-001**: Audit for `_ =>` catch-all patterns that should be explicit
  - Audited and replaced with explicit variant handling where appropriate
- [x] **ERR-002**: Audit for `unwrap_or_default()` hiding real errors
  - Checked - minimal usage, all justified
- [x] **ERR-003**: Audit for silent `continue` in match arms
  - Audited and added proper logging/error handling
- [x] **ERR-004**: Replace `Type::error()` placeholders with proper errors
  - Reviewed - Type::error() used appropriately for poison types
- [x] **ERR-005**: Ensure all TODO/FIXME comments are addressed or tracked
  - All critical TODOs addressed or tracked in this document

---

## 7. Documentation Improvements

### 7.1 Specification Clarifications [P3] ✅ COMPLETE

Minor spec clarifications identified.

- [x] **SPEC-001**: Add integration status column to MEMORY_MODEL.md pointer layout
  - Added A.1 Integration Status by Component table to Appendix A
  - Shows implementation status of each pointer field with location and notes
- [x] **SPEC-002**: Add runtime linking requirements to CONCURRENCY.md
  - Added Section 11: Runtime Linking Requirements
  - Covers required libraries, symbols, platform-specific linking, build integration
- [x] **SPEC-003**: Clarify validated platforms in FFI.md
  - Added Section 9.4: Platform Validation Status
  - Tables for CI-validated, supported but not CI-validated, and experimental platforms
  - Added test coverage table and platform-specific caveats
- [x] **SPEC-004**: Sync README.md version with IMPLEMENTATION_STATUS.md (0.5.0 vs 0.5.2)
  - Updated README.md to version 0.5.2

### 7.2 User Documentation [P2]

- [x] **USERDOC-001**: Expand GETTING_STARTED.md with more examples
  *Added 12 new comprehensive example sections:*
  - *Vectors and HashMaps with full API usage*
  - *Pattern matching with enums, ranges, and wildcards*
  - *Option and Result types with combinators*
  - *Generic functions with trait bounds*
  - *Traits and implementations*
  - *Error handling with effects*
  - *State effect with handlers*
  - *Recursive data structures (binary tree, linked list)*
  - *Iterator adapters (map, filter, fold, chaining)*
- [x] **USERDOC-002**: Create effect system tutorial with common patterns *(Created EFFECTS_TUTORIAL.md with 7 sections: intro, basic effects, handlers, common patterns (state, error, logging, resources, choice), composition, performance, best practices)*
- [x] **USERDOC-003**: Create memory model guide for users *(Created MEMORY_GUIDE.md with 8 sections: overview, memory tiers, generational references, regions, effects integration, performance tips, common patterns, troubleshooting)*
- [x] **USERDOC-004**: Document performance best practices *(Created PERFORMANCE_GUIDE.md with 8 sections: performance model, measured costs, memory optimization, effect handler optimization, data structure choices, anti-patterns, profiling, when to optimize)*
- [x] **USERDOC-005**: Create migration guide from Rust patterns
  *Created RUST_MIGRATION.md with 10 sections:*
  - *Overview (key differences, why migrate, what stays the same)*
  - *Syntax differences (variables, functions, structs, enums, closures)*
  - *Ownership and borrowing (no lifetimes, move semantics)*
  - *Error handling (Result vs Effects, propagation, multiple error types)*
  - *Traits to effects (dependency injection, Iterator trait)*
  - *Concurrency (async/await vs fibers, channels, shared state)*
  - *Memory management (Box/Rc/Arc vs tiers, regions)*
  - *Pattern matching (identical syntax)*
  - *Common patterns (builder, RAII, From/Into, interior mutability)*
  - *Crate to module migration (structure, imports, visibility)*

---

## 8. Risk Mitigation

### 8.1 Single-Maintainer Risk [P1]

Project appears to have single maintainer.

- [x] **RISK-001**: Document all non-obvious design decisions *(Added ADR-022, ADR-023, ADR-024 for slot registry, MIR, and closure capture decisions)*
- [x] **RISK-002**: Create comprehensive contributor documentation *(Created CONTRIBUTING.md with 8 sections: getting started, project structure, development workflow, compiler architecture, testing, code style, PR process, finding issues)*
- [x] **RISK-003**: Add inline comments explaining complex algorithms *(Added algorithm documentation to lower_pattern in patterns.rs, check_tuple_exhaustiveness and check_array_exhaustiveness in exhaustiveness.rs)*
- [x] **RISK-004**: Establish code review process for contributions
  *Expanded CONTRIBUTING.md with comprehensive code review guidelines:*
  - *Review checklist (correctness, safety, testing, design, docs, performance)*
  - *Guidelines for authors and reviewers*
  - *Review labels and merge requirements*
  - *Response time expectations*
- [x] **RISK-005**: Create project governance documentation
  *Created GOVERNANCE.md with:*
  - *Role definitions (Project Lead, Maintainers, Contributors)*
  - *Decision-making processes for routine, significant, and breaking changes*
  - *Design philosophy alignment requirements*
  - *Release process and versioning*
  - *Conflict resolution and succession planning*

### 8.2 Technical Debt [P2] ✅ MOSTLY COMPLETE

- [x] **DEBT-001**: Address all `TODO` comments in codebase
  - 0 TODO comments remain in bloodc/src
- [x] **DEBT-002**: Address all `FIXME` comments in codebase
  - 0 FIXME comments remain in bloodc/src
- [x] **DEBT-003**: Remove dead code identified by tooling
  - No dead_code warnings from cargo build
- [x] **DEBT-004**: Update dependencies to latest stable versions
  *Reviewed 2026-01-14: No security vulnerabilities found (cargo audit clean)*
  - **Unmaintained warnings only** (via sled transitive deps): atomic-polyfill, fxhash, instant
  - **Major version updates available** but require code changes: bitflags 1→2, rand 0.8→0.9, criterion 0.5→0.8
  - **Minor updates available**: nix 0.28→0.30, libloading 0.8→0.9, windows 0.54→0.62
  - **Decision**: No breaking changes needed; unmaintained deps are stable and used only in sled (embedded DB)
  - **Recommendation**: Consider replacing sled with alternative DB if active maintenance required
- [x] **DEBT-005**: Run `cargo audit` and address vulnerabilities
  - No security vulnerabilities found; only unmaintained crate warnings

---

## Summary Statistics

**Status as of 2026-01-14 (Audited):**

| Category | P0 | P1 | P2 | P3 | Completed | Remaining |
|----------|----|----|----|----|-----------|-----------|
| Missing Features | 0 | 0 | 0 | 0 | 17 | **1 partial** |
| Validation Gaps | 0 | 0 | 0 | 0 | 23 | **0** |
| Code Quality | 0 | 0 | 0 | 0 | 13 | **0** |
| Design Concerns | 0 | 0 | 0 | 0 | 16 | **0** |
| Ecosystem | 0 | 2 | 0 | 0 | 20 | **2** |
| Safety | 0 | 0 | 0 | 4 | 10 | **4** |
| Documentation | 0 | 0 | 0 | 0 | 9 | **0** |
| Risk Mitigation | 0 | 0 | 0 | 0 | 10 | **0** |
| **Total** | **0** | **2** | **0** | **4** | **118** | **6 + 1 partial** |

**Note:** Some items marked "complete" were research/investigation tasks with follow-up implementation work. Those implementation tasks are tracked in ACTION_ITEMS.md (v2).

**Key Progress:**
- ✅ All P0 items complete (IMPL-001-007, FFI-001-007, TEST-001-009)
- ✅ Error handling audit complete (ERR-001-005)
- ✅ Self-hosting subset identified (SELF-001)
- ✅ Comprehensive stdlib tests added (STD-006)
- ✅ Memory pressure benchmarks added (PERF-004)
- ✅ Getting Started guide expanded with 12 new example sections (USERDOC-001)
- ✅ All documentation items complete (SPEC-001-004, USERDOC-001-005)
- ✅ Rust migration guide created (USERDOC-005)
- ✅ Deep handler nesting warnings (EFF-003)
- ✅ Snapshot overhead documentation (SNAP-005)
- ✅ Networking primitives implemented (STD-005)
- ✅ Standard library core complete (STD-001-006)
- ✅ Technical debt addressed (DEBT-001-003, DEBT-005)
- ✅ Module documentation complete (DOC-001, CODE-005)
- ✅ Performance benchmarks added (PERF-001, PERF-002, PERF-003, PTR-001, PTR-006)
- ✅ User documentation expanded (USERDOC-002, USERDOC-003, USERDOC-004)
- ✅ Contributor documentation complete (RISK-002, DOC-002, DOC-003)
- ✅ Standard library core types complete (STD-001, STD-002, STD-003, STD-004)
- ✅ Real-world validation: JSON parser (REAL-001), HTTP client (REAL-002), web scraper (REAL-003), CLBG benchmarks (REAL-005)
- ✅ Effect system performance documentation complete (EFF-005)
- ✅ Pointer-heavy anti-pattern warnings added (PTR-005)
- ✅ Cross-language benchmark comparison complete (PERF-006)
- ✅ MIR lowering duplication audit complete (DUP-001)
- ✅ Closure environment size analysis complete (CLOS-001)
- ✅ Closure capture escape analysis complete (CLOS-002)
- ✅ Evidence vector allocation audit complete (EFF-001)
- ✅ MIR lowering utilities extracted to shared module (DUP-002)
- ✅ Evidence vector caching for repeated handler patterns (EFF-002)
- ✅ Lazy validation optimization for generation snapshots (SNAP-001)
- ✅ Escape analysis optimization effectiveness benchmarked (PERF-005)
- ✅ Effect-heavy program snapshot overhead profiled (SNAP-003)
- ✅ Evidence lookup hot path overhead profiled (EFF-004)
- ✅ Liveness filtering for snapshot size reduction (SNAP-004)
- ✅ Property tests for escape analysis soundness (FUZZ-005)
- ✅ Property tests for MIR lowering correctness (FUZZ-004)
- ✅ Fuzzer coverage expanded with 3 new targets (FUZZ-001)
- ✅ MIR visitor infrastructure for analysis passes (DUP-004)
- ✅ Blood lexer implemented in Blood for self-hosting (SELF-002)
- ✅ Content-addressed build caching complete (BUILD-001)
- ✅ Incremental compilation using content hashes (BUILD-002)
- ✅ Distributed HTTP-based build cache (BUILD-003)
- ✅ blood-fmt auto-formatting tool complete (TOOL-004)
- ✅ Dispatch module refactored into 8 submodules (CODE-004)
- ✅ Snapshot sharing for nested handlers (SNAP-002)
- ✅ Multi-file project support with Blood.toml (BUILD-004)
- ✅ Grammar-based fuzzing for parser (FUZZ-002)
- ✅ Thin pointer optimization investigation complete (PTR-002)
- ✅ Optional 64-bit mode design analysis complete (PTR-004)
- ✅ LSP hover documentation with 40+ keywords and examples (TOOL-001)
- ✅ LSP go-to-definition for effect operations verified and tested (TOOL-002)
- ✅ Package manager foundation complete with semver, lockfile, resolver, fetcher, cache (BUILD-005)
- ✅ Blood parser implemented in Blood for self-hosting (SELF-003)

---

## Recommended Execution Order

### Phase 1: Critical Path (P0 items) ✅ COMPLETE
1. ~~Persistent memory tier (IMPL-001 through IMPL-007)~~ ✅
2. ~~FFI code generation (FFI-001 through FFI-007)~~ ✅
3. ~~Integration tests for novel features (TEST-001 through TEST-009)~~ ✅

### Phase 2: Beta Readiness (P1 items) — NEXT
1. Real-world validation programs (REAL-001 through REAL-007)
2. Performance benchmarks (PERF-001 through PERF-007)
3. Closures enhancement (CLOS-001 through CLOS-004)
4. Self-hosting progress (SELF-001 through SELF-005)
5. Standard library completion (STD-001 through STD-006)
6. 128-bit pointer profiling (PTR-001 through PTR-006)
7. Single-maintainer risk mitigation (RISK-001 through RISK-005)

### Phase 3: 1.0 Release (P2 items)
1. Design optimizations (EFF-001-005, SNAP-001-005) — ✅ COMPLETE
2. Developer tooling polish (TOOL-001-003, TOOL-005-006) — TOOL-004 ✅
3. Build system (BUILD-001-005) — ✅ ALL COMPLETE
4. Fuzzing and property testing (FUZZ-001-005) — ✅ ALL COMPLETE
5. Large file modularization (CODE-004) — ✅ COMPLETE
6. User documentation — ✅ COMPLETE

### Phase 4: Long-term (P3 items)
1. Formal verification (FORMAL-001-004)
2. Specification polish (SPEC-001-003)
3. Contributor documentation (DOC-002-004)

---

*This document should be reviewed and updated as items are completed.*
