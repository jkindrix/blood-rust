# Blood Concurrency Specification

**Version**: 0.3.0
**Status**: Implemented
**Implementation**: âœ… Integrated (see [IMPLEMENTATION_STATUS.md](./IMPLEMENTATION_STATUS.md))
**Last Updated**: 2026-01-10

**Implementation Status**: Runtime is implemented and linked to compiled programs. See [IMPLEMENTATION_STATUS.md](./IMPLEMENTATION_STATUS.md) for current status. Performance benchmarks are ongoing.

**Revision 0.3.0 Changes**:
- Added implementation status link
- Updated implementation status to reflect runtime integration

This document specifies Blood's concurrency model, including fiber semantics, scheduling, synchronization primitives, and parallel execution.

---

## Table of Contents

1. [Overview](#1-overview)
2. [Fiber Model](#2-fiber-model)
3. [Scheduler](#3-scheduler)
4. [Fiber Lifecycle](#4-fiber-lifecycle)
5. [Communication](#5-communication)
6. [Synchronization](#6-synchronization)
7. [Parallel Primitives](#7-parallel-primitives)
8. [Effect Integration](#8-effect-integration)
9. [Memory Model](#9-memory-model)
10. [Platform Mapping](#10-platform-mapping)
11. [Runtime Linking Requirements](#11-runtime-linking-requirements)

---

## 1. Overview

### 1.1 Design Goals

Blood's concurrency model provides:

1. **Lightweight Concurrency** â€” Millions of concurrent fibers
2. **Cooperative Scheduling** â€” Predictable yield points
3. **Memory Safety** â€” No data races by construction
4. **Effect Integration** â€” Concurrency as an effect
5. **Structured Concurrency** â€” Child fibers complete before parent

### 1.2 Related Specifications

- [SPECIFICATION.md](./SPECIFICATION.md) â€” Core language specification
- [MEMORY_MODEL.md](./MEMORY_MODEL.md) â€” Region-fiber isolation rules
- [STDLIB.md](./STDLIB.md) â€” Fiber and Channel effects
- [FORMAL_SEMANTICS.md](./FORMAL_SEMANTICS.md) â€” Effect handler semantics
- [FFI.md](./FFI.md) â€” FFI interaction with fibers
- [ROADMAP.md](./ROADMAP.md) â€” Runtime implementation phases

### 1.3 Implementation Status

The following table tracks implementation status of concurrency subsystems:

| Component | Status | Location | Notes |
|-----------|--------|----------|-------|
| FiberId, FiberState | âœ… Implemented | `blood-runtime/src/fiber.rs` | Core fiber identity |
| FiberConfig | âœ… Implemented | `blood-runtime/src/fiber.rs` | Stack size, priority |
| FiberStack | âœ… Implemented | `blood-runtime/src/fiber.rs` | Growable stack |
| WakeCondition | âœ… Implemented | `blood-runtime/src/fiber.rs` | Channel, timer, IO |
| Scheduler | âœ… Implemented | `blood-runtime/src/scheduler.rs` | Work-stealing M:N |
| Worker threads | âœ… Implemented | `blood-runtime/src/scheduler.rs` | Per-core workers |
| blood_scheduler_* exports | âœ… Integrated | `blood-runtime/src/ffi_exports.rs` | Runtime scheduler FFI |
| MPMC channels | âœ… Implemented | `blood-runtime/src/channel.rs` | Bounded/unbounded |
| I/O reactor | âœ… Implemented | `blood-runtime/src/io.rs` | Platform-native async |
| Platform: Linux epoll | âœ… Implemented | `blood-runtime/src/io.rs` | Fallback driver |
| Platform: Linux io_uring | âœ… Implemented | `blood-runtime/src/io.rs` | Primary Linux driver |
| Platform: macOS kqueue | âœ… Implemented | `blood-runtime/src/io.rs` | Primary macOS driver |
| Platform: Windows IOCP | âœ… Implemented | `blood-runtime/src/io.rs` | Primary Windows driver |
| Fiber effect syntax | âœ… Implemented | `blood-std/std/effects/fiber.blood` | Per Â§2.4 specification |
| Structured concurrency | âœ… Implemented | `blood-std/std/effects/fiber.blood` | Nursery, FiberScope, par_map, etc. |
| Select/await syntax | âœ… Implemented | `blood-std/std/effects/fiber.blood` | SelectBuilder, await_first, select_timeout |

**Legend**: âœ… Implemented | ğŸ”¶ Partial | ğŸ“‹ Designed | âŒ Not Started

### 1.4 Concurrency Philosophy

| Aspect | Blood Approach |
|--------|----------------|
| **Unit of Concurrency** | Fibers (stackful coroutines) |
| **Scheduling** | M:N cooperative with preemption points |
| **Communication** | Channels (typed, bounded) |
| **Shared State** | By default: none. Opt-in via `Synchronized<T>` |
| **Memory** | Fiber-local regions, shared via Tier 3 |

### 1.5 Comparison with Other Models

| Feature | Blood | Go | Erlang | Rust async |
|---------|-------|----|----|------------|
| **Concurrency Unit** | Fiber | Goroutine | Process | Task |
| **Stack** | Growable | Growable | Per-process | Stackless |
| **Scheduling** | M:N | M:N | M:N | M:N |
| **Communication** | Channels | Channels | Messages | Channels |
| **Shared Memory** | Opt-in | Yes | None | Yes (unsafe) |
| **GC** | None | Yes | Yes | None |

---

## 2. Fiber Model

### 2.1 What is a Fiber?

A **fiber** is a lightweight, cooperatively-scheduled unit of execution:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           FIBER                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚ Stack       â”‚    â”‚ Registers   â”‚    â”‚ State       â”‚       â”‚
â”‚  â”‚ (growable)  â”‚    â”‚ (saved)     â”‚    â”‚             â”‚       â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤       â”‚
â”‚  â”‚ Local       â”‚    â”‚ PC, SP      â”‚    â”‚ Running     â”‚       â”‚
â”‚  â”‚ Variables   â”‚    â”‚ FP, etc.    â”‚    â”‚ Suspended   â”‚       â”‚
â”‚  â”‚             â”‚    â”‚             â”‚    â”‚ Completed   â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ Regions (Fiber-Local Memory)                         â”‚     â”‚
â”‚  â”‚ - Stack allocations                                  â”‚     â”‚
â”‚  â”‚ - Heap allocations (Tier 1)                          â”‚     â”‚
â”‚  â”‚ - Cannot be accessed by other fibers                 â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 Fiber Properties

| Property | Value | Status |
|----------|-------|--------|
| **Initial Stack Size** | 8 KB (configurable) | Design target |
| **Maximum Stack Size** | 1 MB (configurable) | Design target |
| **Stack Growth** | On-demand, 2x growth factor | Design target |
| **Context Switch Cost** | ~50-100 ns (register save/restore) | UnvalidatedÂ¹ |
| **Memory Overhead** | ~1-2 KB per suspended fiber | UnvalidatedÂ¹ |

Â¹ Performance estimates based on similar fiber implementations (Go goroutines, Tokio tasks). Actual performance will be validated during implementation.

### 2.3 Fiber Structure

```rust
struct Fiber {
    // Identity
    id: FiberId,
    parent: Option<FiberId>,

    // Execution state
    state: FiberState,
    stack: Stack,
    registers: SavedRegisters,

    // Scheduling
    priority: Priority,
    wake_condition: Option<WakeCondition>,

    // Memory
    local_regions: Vec<RegionId>,
    tier3_refs: Vec<Hash>,  // Shared data references

    // Effect handling
    installed_handlers: Vec<HandlerId>,
    suspended_at: Option<EffectOp>,

    // Debugging
    name: Option<String>,
    created_at: Timestamp,
}

enum FiberState {
    /// Ready to run
    Runnable,

    /// Currently executing on a worker thread
    Running(WorkerId),

    /// Waiting for an event
    Suspended(WakeCondition),

    /// Waiting for child fibers
    Joining(Vec<FiberId>),

    /// Completed successfully
    Completed(Value),

    /// Failed with error
    Failed(Error),

    /// Cancelled
    Cancelled,
}

enum WakeCondition {
    /// Channel has data
    ChannelReadable(ChannelId),

    /// Channel has space
    ChannelWritable(ChannelId),

    /// Timer expired
    Timeout(Instant),

    /// I/O ready
    IoReady(Fd, IoInterest),

    /// Effect resumed
    EffectResumed,

    /// Any of these conditions
    Any(Vec<WakeCondition>),
}
```

### 2.4 Fiber Creation

```blood
effect Fiber {
    /// Spawn a new fiber
    op spawn<T>(f: fn() -> T / {Fiber | Îµ}) -> FiberHandle<T>;

    /// Spawn with configuration
    op spawn_with<T>(
        config: FiberConfig,
        f: fn() -> T / {Fiber | Îµ}
    ) -> FiberHandle<T>;

    /// Get current fiber's handle
    op current() -> FiberHandle<()>;

    /// Yield to scheduler
    op yield();

    /// Sleep for duration
    op sleep(duration: Duration);
}

struct FiberConfig {
    name: Option<String>,
    stack_size: usize,
    priority: Priority,
}

struct FiberHandle<T> {
    id: FiberId,
    // Phantom type for result
    _phantom: PhantomData<T>,
}
```

### 2.5 Fiber Syntax

```blood
fn example() / {Fiber, IO} {
    // Spawn a fiber
    let handle = spawn(|| {
        heavy_computation()
    });

    // Do other work concurrently
    let local_result = light_computation();

    // Wait for fiber to complete
    let fiber_result = await(handle);

    (local_result, fiber_result)
}

// Named fiber with configuration
fn configured_example() / {Fiber} {
    let handle = spawn_with(
        FiberConfig {
            name: Some("worker"),
            stack_size: 64 * 1024,  // 64 KB
            priority: Priority::High,
        },
        || { work() }
    );

    await(handle)
}
```

---

## 3. Scheduler

### 3.1 M:N Scheduling

Blood uses M:N scheduling: M fibers mapped to N OS threads.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       RUNTIME SCHEDULER                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚                   RUN QUEUES                           â”‚      â”‚
â”‚  â”‚                                                        â”‚      â”‚
â”‚  â”‚  Global: [ F1 ]â”€â”€[ F5 ]â”€â”€[ F9 ]                        â”‚      â”‚
â”‚  â”‚                                                        â”‚      â”‚
â”‚  â”‚  Local (Worker 0): [ F2 ]â”€â”€[ F6 ]                      â”‚      â”‚
â”‚  â”‚  Local (Worker 1): [ F3 ]â”€â”€[ F7 ]                      â”‚      â”‚
â”‚  â”‚  Local (Worker 2): [ F4 ]â”€â”€[ F8 ]                      â”‚      â”‚
â”‚  â”‚                                                        â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                          â†“                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚                   WORKER THREADS                       â”‚      â”‚
â”‚  â”‚                                                        â”‚      â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚      â”‚
â”‚  â”‚  â”‚ Worker 0â”‚    â”‚ Worker 1â”‚    â”‚ Worker 2â”‚    ...     â”‚      â”‚
â”‚  â”‚  â”‚ (Core 0)â”‚    â”‚ (Core 1)â”‚    â”‚ (Core 2)â”‚            â”‚      â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚      â”‚
â”‚  â”‚       â†“              â†“              â†“                  â”‚      â”‚
â”‚  â”‚  OS Thread 0    OS Thread 1    OS Thread 2             â”‚      â”‚
â”‚  â”‚                                                        â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.2 Scheduler Structure

```rust
struct Scheduler {
    // Worker threads
    workers: Vec<Worker>,
    num_workers: usize,

    // Global run queue (for load balancing)
    global_queue: ConcurrentQueue<FiberId>,

    // Sleeping fibers (timer heap)
    timer_heap: BinaryHeap<(Instant, FiberId)>,

    // I/O reactor
    io_reactor: IoReactor,

    // Statistics
    stats: SchedulerStats,

    // Shutdown coordination
    shutdown: AtomicBool,
}

struct Worker {
    id: WorkerId,

    // Local run queue (work stealing)
    local_queue: WorkStealingQueue<FiberId>,

    // Currently running fiber
    current_fiber: Option<FiberId>,

    // Random number generator (for work stealing)
    rng: FastRng,

    // Statistics
    stats: WorkerStats,
}
```

### 3.3 Scheduling Algorithm

```
SCHEDULER_LOOP(worker):
    LOOP:
        // 1. Check local queue first
        fiber â† worker.local_queue.pop()

        IF fiber.is_none():
            // 2. Try global queue
            fiber â† scheduler.global_queue.pop()

        IF fiber.is_none():
            // 3. Try to steal from other workers
            victim â† worker.rng.select_victim(scheduler.workers)
            fiber â† victim.local_queue.steal()

        IF fiber.is_none():
            // 4. Park until work available
            PARK(worker)
            CONTINUE

        // Run the fiber
        result â† RUN_FIBER(fiber)

        MATCH result:
            | Yielded â†’ worker.local_queue.push(fiber)
            | Suspended(cond) â†’ REGISTER_WAKE(fiber, cond)
            | Completed(val) â†’ COMPLETE_FIBER(fiber, val)
            | Failed(err) â†’ FAIL_FIBER(fiber, err)
```

### 3.4 Yield Points

Fibers yield cooperatively at defined points:

| Yield Point | Trigger |
|-------------|---------|
| `yield()` | Explicit yield |
| `await(handle)` | Waiting for another fiber |
| `channel.send()` | Channel full |
| `channel.recv()` | Channel empty |
| `sleep(duration)` | Timer |
| `perform(effect)` | Effect operation |
| Function call | Optional preemption check |

### 3.5 Preemption

For long-running computations, Blood inserts preemption checks:

```blood
// Compiler inserts preemption checks at:
// - Function entry (if loop body)
// - Loop back edges
// - After N instructions (configurable)

#[preemption_check]
fn long_loop() / {Fiber} {
    for i in 0..1_000_000 {
        // Preemption check inserted here by compiler
        compute(i);
    }
}
```

Implementation:

```
PREEMPTION_CHECK():
    IF current_fiber.should_yield:
        current_fiber.should_yield â† false
        yield()
```

### 3.6 Priority Scheduling

```rust
enum Priority {
    Low = 0,
    Normal = 1,      // Default
    High = 2,
    Critical = 3,    // For system fibers
}

impl Scheduler {
    fn select_fiber(&self) -> Option<FiberId> {
        // Higher priority fibers run first
        for priority in [Critical, High, Normal, Low] {
            if let Some(fiber) = self.get_runnable(priority) {
                return Some(fiber);
            }
        }
        None
    }
}
```

---

## 4. Fiber Lifecycle

### 4.1 State Machine

```
                    spawn()
                       â”‚
                       â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   Runnable     â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
                      â”‚                     â”‚
                 schedule                   â”‚ wake
                      â”‚                     â”‚
                      â–¼                     â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
              â”‚    Running     â”‚           â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
                      â”‚                     â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
         â”‚            â”‚            â”‚       â”‚
    complete     suspend        yield      â”‚
         â”‚            â”‚            â”‚       â”‚
         â–¼            â–¼            â”‚       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚       â”‚
â”‚  Completed   â”‚ â”‚  Suspended   â”‚â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                â”‚
         â”‚           cancel
         â”‚                â”‚
         â–¼                â–¼
      (done)       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚  Cancelled   â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4.2 Spawn Operation

```
SPAWN(f):
    // 1. Allocate fiber
    fiber_id â† allocate_fiber_id()
    stack â† allocate_stack(INITIAL_STACK_SIZE)

    fiber â† Fiber {
        id: fiber_id,
        parent: current_fiber_id(),
        state: Runnable,
        stack,
        // ...
    }

    // 2. Initialize stack with trampoline
    setup_trampoline(fiber, f)

    // 3. Add to parent's children (structured concurrency)
    current_fiber.children.push(fiber_id)

    // 4. Add to run queue
    scheduler.local_queue.push(fiber_id)

    // 5. Return handle
    RETURN FiberHandle { id: fiber_id }
```

### 4.3 Await Operation

```
AWAIT(handle):
    target â† get_fiber(handle.id)

    MATCH target.state:
        | Completed(value) â†’
            RETURN value

        | Failed(error) â†’
            RAISE error

        | Cancelled â†’
            RAISE CancelledError

        | _ â†’
            // Suspend current fiber until target completes
            current_fiber.state â† Joining([handle.id])
            YIELD_TO_SCHEDULER()

            // When resumed, target has completed
            RETURN AWAIT(handle)  // Retry
```

### 4.4 Structured Concurrency

All child fibers must complete before their parent:

```blood
fn structured_example() / {Fiber} {
    let h1 = spawn(|| task1());
    let h2 = spawn(|| task2());

    // Implicit: parent waits for h1, h2 before returning
    let r1 = await(h1);
    let r2 = await(h2);

    (r1, r2)
}
// h1 and h2 guaranteed complete here

// Nursery pattern for explicit scoping
fn nursery_example() / {Fiber} {
    nursery(|scope| {
        scope.spawn(|| task1());
        scope.spawn(|| task2());
        scope.spawn(|| task3());
        // All tasks complete when nursery exits
    })
}
```

### 4.5 Cancellation

```blood
effect Cancel {
    /// Check if cancellation requested
    op is_cancelled() -> bool;

    /// Throw if cancelled
    op check_cancelled();
}

fn cancellable_task() / {Fiber, Cancel} {
    for item in items {
        check_cancelled();  // Cancellation point
        process(item);
    }
}

fn cancel_example() / {Fiber} {
    let handle = spawn(|| cancellable_task());

    // Cancel after timeout
    sleep(Duration::seconds(5));
    cancel(handle);

    // Wait for cancellation to complete
    match await_cancellable(handle) {
        Ok(result) => result,
        Err(Cancelled) => default_value(),
    }
}
```

Implementation:

```
CANCEL(handle):
    fiber â† get_fiber(handle.id)

    // Set cancellation flag
    fiber.cancel_requested â† true

    // If suspended, wake it up
    IF fiber.state == Suspended(_):
        fiber.state â† Runnable
        scheduler.enqueue(fiber.id)

    // Cancellation is cooperative - fiber must check
```

---

## 5. Communication

### 5.1 Channels

Channels are typed, bounded queues for fiber communication:

```blood
effect Channel<T> {
    /// Create a new channel
    op channel<T>(capacity: usize) -> (Sender<T>, Receiver<T>);

    /// Send a value (blocks if full)
    op send(value: T);

    /// Receive a value (blocks if empty)
    op recv() -> T;

    /// Try operations (non-blocking)
    op try_send(value: T) -> Result<(), Full<T>>;
    op try_recv() -> Result<T, Empty>;
}

fn channel_example() / {Fiber, Channel<i32>} {
    let (tx, rx) = channel(10);  // Capacity 10

    spawn(move || {
        for i in 0..100 {
            tx.send(i);  // Blocks if full
        }
        drop(tx);  // Close sender
    });

    loop {
        match rx.try_recv() {
            Ok(value) => process(value),
            Err(Empty) => yield(),
            Err(Closed) => break,
        }
    }
}
```

### 5.2 Channel Implementation

```rust
struct Channel<T> {
    // Bounded buffer
    buffer: ArrayQueue<T>,
    capacity: usize,

    // Waiting senders/receivers
    waiting_senders: WaitList<FiberId>,
    waiting_receivers: WaitList<FiberId>,

    // State
    closed: AtomicBool,
    sender_count: AtomicUsize,
    receiver_count: AtomicUsize,
}

impl<T> Channel<T> {
    fn send(&self, value: T) -> Result<(), Closed> {
        loop {
            if self.closed.load() {
                return Err(Closed);
            }

            if self.buffer.push(value).is_ok() {
                // Wake a waiting receiver
                if let Some(fiber) = self.waiting_receivers.pop() {
                    scheduler.wake(fiber);
                }
                return Ok(());
            }

            // Buffer full - wait
            self.waiting_senders.push(current_fiber_id());
            suspend(ChannelWritable(self.id));
        }
    }

    fn recv(&self) -> Result<T, Closed> {
        loop {
            if let Some(value) = self.buffer.pop() {
                // Wake a waiting sender
                if let Some(fiber) = self.waiting_senders.pop() {
                    scheduler.wake(fiber);
                }
                return Ok(value);
            }

            if self.closed.load() && self.buffer.is_empty() {
                return Err(Closed);
            }

            // Buffer empty - wait
            self.waiting_receivers.push(current_fiber_id());
            suspend(ChannelReadable(self.id));
        }
    }
}
```

### 5.3 Channel Patterns

```blood
// Fan-out: one producer, multiple consumers
fn fan_out() / {Fiber} {
    let (tx, rx) = channel(100);

    // Spawn workers
    for _ in 0..4 {
        let rx = rx.clone();
        spawn(move || worker(rx));
    }

    // Produce work
    for item in work_items {
        tx.send(item);
    }
}

// Fan-in: multiple producers, one consumer
fn fan_in() / {Fiber} {
    let (tx, rx) = channel(100);

    // Spawn producers
    for source in sources {
        let tx = tx.clone();
        spawn(move || producer(source, tx));
    }
    drop(tx);  // Drop original sender

    // Consume all
    while let Ok(item) = rx.recv() {
        process(item);
    }
}

// Pipeline: chain of processing stages
fn pipeline() / {Fiber} {
    let (tx1, rx1) = channel(10);
    let (tx2, rx2) = channel(10);
    let (tx3, rx3) = channel(10);

    spawn(|| stage1(tx1));
    spawn(|| stage2(rx1, tx2));
    spawn(|| stage3(rx2, tx3));

    collect(rx3)
}
```

### 5.4 Select

Wait on multiple channel operations:

```blood
fn select_example() / {Fiber} {
    let (tx1, rx1) = channel(10);
    let (tx2, rx2) = channel(10);

    loop {
        select! {
            value = rx1.recv() => {
                handle_type1(value);
            },
            value = rx2.recv() => {
                handle_type2(value);
            },
            default => {
                // No channel ready
                yield();
            },
            timeout(Duration::seconds(1)) => {
                // Timeout
                break;
            },
        }
    }
}
```

---

## 6. Synchronization

### 6.1 Mutex

For shared mutable state (use sparingly):

```blood
struct Mutex<T> {
    value: UnsafeCell<T>,
    locked: AtomicBool,
    waiters: WaitList<FiberId>,
}

impl<T> Mutex<T> {
    fn new(value: T) -> Mutex<T> { ... }

    fn lock(&self) -> MutexGuard<T> / {Fiber} {
        loop {
            if self.locked.compare_exchange(false, true).is_ok() {
                return MutexGuard { mutex: self };
            }
            // Wait for unlock
            self.waiters.push(current_fiber_id());
            suspend(MutexUnlocked(self.id));
        }
    }

    fn try_lock(&self) -> Option<MutexGuard<T>> {
        if self.locked.compare_exchange(false, true).is_ok() {
            Some(MutexGuard { mutex: self })
        } else {
            None
        }
    }
}

impl<T> Drop for MutexGuard<T> {
    fn drop(&mut self) {
        self.mutex.locked.store(false);
        // Wake one waiter
        if let Some(fiber) = self.mutex.waiters.pop() {
            scheduler.wake(fiber);
        }
    }
}
```

### 6.2 RwLock

Reader-writer lock:

```blood
struct RwLock<T> {
    value: UnsafeCell<T>,
    state: AtomicIsize,  // Positive = readers, -1 = writer
    waiting_writers: WaitList<FiberId>,
    waiting_readers: WaitList<FiberId>,
}

impl<T> RwLock<T> {
    fn read(&self) -> ReadGuard<T> / {Fiber} { ... }
    fn write(&self) -> WriteGuard<T> / {Fiber} { ... }
}
```

### 6.3 Semaphore

```blood
struct Semaphore {
    permits: AtomicUsize,
    waiters: WaitList<FiberId>,
}

impl Semaphore {
    fn new(permits: usize) -> Semaphore { ... }

    fn acquire(&self) / {Fiber} {
        loop {
            let current = self.permits.load();
            if current > 0 {
                if self.permits.compare_exchange(current, current - 1).is_ok() {
                    return;
                }
            } else {
                self.waiters.push(current_fiber_id());
                suspend(SemaphoreAvailable(self.id));
            }
        }
    }

    fn release(&self) {
        self.permits.fetch_add(1);
        if let Some(fiber) = self.waiters.pop() {
            scheduler.wake(fiber);
        }
    }
}
```

### 6.4 Barrier

```blood
struct Barrier {
    count: usize,
    waiting: AtomicUsize,
    generation: AtomicUsize,
    waiters: WaitList<FiberId>,
}

impl Barrier {
    fn wait(&self) / {Fiber} {
        let gen = self.generation.load();
        let arrived = self.waiting.fetch_add(1) + 1;

        if arrived == self.count {
            // Last to arrive - release all
            self.waiting.store(0);
            self.generation.fetch_add(1);
            for fiber in self.waiters.drain() {
                scheduler.wake(fiber);
            }
        } else {
            // Wait for others
            self.waiters.push(current_fiber_id());
            loop {
                suspend(BarrierReleased(self.id));
                if self.generation.load() != gen {
                    break;
                }
            }
        }
    }
}
```

### 6.5 Once

```blood
struct Once {
    state: AtomicU8,  // 0 = uninitialized, 1 = initializing, 2 = initialized
    waiters: WaitList<FiberId>,
}

impl Once {
    fn call_once<F: FnOnce()>(&self, f: F) / {Fiber} {
        match self.state.load() {
            2 => return,  // Already initialized
            1 => {
                // Another fiber is initializing - wait
                self.waiters.push(current_fiber_id());
                suspend(OnceInitialized(self.id));
                return;
            }
            0 => {
                if self.state.compare_exchange(0, 1).is_ok() {
                    f();
                    self.state.store(2);
                    for fiber in self.waiters.drain() {
                        scheduler.wake(fiber);
                    }
                } else {
                    self.call_once(f);  // Retry
                }
            }
        }
    }
}
```

---

## 7. Parallel Primitives

### 7.1 Parallel Iterators

```blood
trait ParallelIterator<T> {
    fn par_map<U, F>(self, f: F) -> ParMap<T, U, F>
    where F: Fn(T) -> U + Send;

    fn par_filter<F>(self, f: F) -> ParFilter<T, F>
    where F: Fn(&T) -> bool + Send;

    fn par_reduce<F>(self, identity: T, f: F) -> T
    where F: Fn(T, T) -> T + Send;

    fn par_for_each<F>(self, f: F)
    where F: Fn(T) + Send;
}

impl<T: Send> ParallelIterator<T> for Vec<T> {
    fn par_map<U, F>(self, f: F) -> Vec<U> / {Fiber}
    where F: Fn(T) -> U + Send {
        let num_chunks = num_workers();
        let chunk_size = (self.len() + num_chunks - 1) / num_chunks;

        let results: Vec<FiberHandle<Vec<U>>> = self
            .chunks(chunk_size)
            .map(|chunk| spawn(move || chunk.iter().map(&f).collect()))
            .collect();

        results.into_iter()
            .flat_map(|h| await(h))
            .collect()
    }
}

// Usage
fn parallel_example() / {Fiber} {
    let data: Vec<i32> = (0..1_000_000).collect();

    let squared: Vec<i32> = data.par_map(|x| x * x);

    let sum: i32 = squared.par_reduce(0, |a, b| a + b);

    sum
}
```

### 7.2 Parallel Scope

```blood
fn parallel_scope<R>(f: fn(&Scope) -> R) -> R / {Fiber} {
    let scope = Scope::new();
    let result = f(&scope);
    scope.wait_all();  // Structured concurrency
    result
}

struct Scope {
    fibers: Vec<FiberHandle<()>>,
}

impl Scope {
    fn spawn<F>(&mut self, f: F)
    where F: FnOnce() + Send {
        self.fibers.push(spawn(f));
    }

    fn wait_all(&self) / {Fiber} {
        for handle in &self.fibers {
            await(handle.clone());
        }
    }
}

// Usage
fn scope_example() / {Fiber} {
    let data = vec![1, 2, 3, 4, 5];
    let results = Mutex::new(Vec::new());

    parallel_scope(|scope| {
        for item in data {
            scope.spawn(move || {
                let r = compute(item);
                results.lock().push(r);
            });
        }
    });

    results.into_inner()
}
```

### 7.3 Work Stealing

```blood
/// Work-stealing deque for load balancing
struct WorkStealingDeque<T> {
    // Owner pushes/pops from bottom
    bottom: AtomicIsize,

    // Stealers steal from top
    top: AtomicIsize,

    // Circular buffer
    buffer: AtomicPtr<[T]>,
}

impl<T> WorkStealingDeque<T> {
    /// Owner: push to bottom
    fn push(&self, item: T) { ... }

    /// Owner: pop from bottom
    fn pop(&self) -> Option<T> { ... }

    /// Thief: steal from top
    fn steal(&self) -> Option<T> { ... }
}
```

---

## 8. Effect Integration

### 8.1 Concurrency as Effects

All concurrency operations are effects:

```blood
effect Fiber {
    op spawn<T>(f: fn() -> T / {Fiber | Îµ}) -> FiberHandle<T>;
    op current() -> FiberHandle<()>;
    op yield();
    op sleep(duration: Duration);
}

effect Async {
    op await<T>(handle: FiberHandle<T>) -> T;
    op select<T>(handles: Vec<FiberHandle<T>>) -> (usize, T);
    op timeout<T>(duration: Duration, f: fn() -> T / {Async | Îµ}) -> Result<T, Timeout>;
}

effect Channel<T> {
    op channel(capacity: usize) -> (Sender<T>, Receiver<T>);
    op send(value: T);
    op recv() -> T;
}
```

### 8.2 Effect Handler Integration

```blood
// Handler for running concurrent code
deep handler FiberRuntime for Fiber {
    let scheduler: Scheduler

    return(x) { x }

    op spawn(f) {
        let handle = scheduler.spawn(f);
        resume(handle)
    }

    op yield() {
        scheduler.yield_current();
        resume(())
    }

    op sleep(duration) {
        scheduler.sleep_current(duration);
        resume(())
    }
}

// Run concurrent computation
fn run<T>(f: fn() -> T / {Fiber}) -> T {
    let scheduler = Scheduler::new();
    with FiberRuntime { scheduler } handle {
        f()
    }
}
```

### 8.3 Fiber + Region Interaction

From MEMORY_MODEL.md Section 7.8:

```blood
// Regions are fiber-local
fn region_fiber_example() / {Fiber} {
    region local_data {
        let buffer = allocate_buffer();  // In local_data region

        // WRONG: Cannot share region reference
        // spawn(|| use_buffer(&buffer));  // COMPILE ERROR

        // CORRECT: Promote to Tier 3
        let shared = persist(buffer.clone());
        spawn(|| use_buffer(&shared));
    }
}
```

---

## 9. Memory Model

### 9.1 Fiber Memory Isolation

Each fiber has isolated memory:

| Memory Type | Visibility | Sharing Mechanism |
|-------------|------------|-------------------|
| Stack | Fiber-local | None |
| Tier 1 (Region) | Fiber-local | None (by design) |
| Tier 3 (Persistent) | Global | Explicit sharing |
| Channels | Shared | Message passing |

### 9.2 Data Race Prevention

Blood prevents data races by construction:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              DATA RACE PREVENTION                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  1. No shared mutable state by default                       â”‚
â”‚     - Fiber-local regions cannot be accessed by others       â”‚
â”‚     - Compiler rejects cross-fiber region references         â”‚
â”‚                                                              â”‚
â”‚  2. Tier 3 sharing requires:                                 â”‚
â”‚     - Frozen (immutable): Read-only, safe to share           â”‚
â”‚     - Synchronized<T>: Mutex-protected mutable               â”‚
â”‚                                                              â”‚
â”‚  3. Channels transfer ownership:                             â”‚
â”‚     - Sent value moves from sender to receiver               â”‚
â”‚     - No aliasing across fiber boundary                      â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 9.3 Memory Ordering

For atomics and synchronization:

| Ordering | Guarantee |
|----------|-----------|
| Relaxed | No ordering (only atomicity) |
| Acquire | Reads cannot move before |
| Release | Writes cannot move after |
| AcqRel | Both acquire and release |
| SeqCst | Total ordering (strongest) |

```blood
fn atomic_example() {
    let counter = AtomicI32::new(0);

    // Relaxed: just need atomicity
    counter.fetch_add(1, Ordering::Relaxed);

    // Release: publish updates
    data.store(value, Ordering::Relaxed);
    flag.store(true, Ordering::Release);

    // Acquire: see published updates
    if flag.load(Ordering::Acquire) {
        let v = data.load(Ordering::Relaxed);
    }
}
```

---

## 10. Platform Mapping

### 10.1 Worker Thread Mapping

| Platform | Worker Threads | Notes |
|----------|---------------|-------|
| Linux | `sched_setaffinity` | Core pinning |
| macOS | `pthread_setaffinity_np` | Limited |
| Windows | `SetThreadAffinityMask` | Full support |
| WASM | Single-threaded | Web Workers planned |

### 10.2 I/O Integration

| Platform | I/O Mechanism |
|----------|--------------|
| Linux | `io_uring` (preferred), `epoll` |
| macOS | `kqueue` |
| Windows | `IOCP` |
| WASM | Browser event loop |

```blood
// Platform-abstracted I/O
effect AsyncIO {
    op read(fd: Fd, buf: &mut [u8]) -> Result<usize, IoError>;
    op write(fd: Fd, buf: &[u8]) -> Result<usize, IoError>;
    op accept(socket: Socket) -> Result<Socket, IoError>;
    op connect(addr: SocketAddr) -> Result<Socket, IoError>;
}
```

### 10.3 Stack Management

```rust
struct Stack {
    // Guard page at bottom (for overflow detection)
    guard: *mut u8,

    // Usable stack area
    base: *mut u8,
    size: usize,

    // Current stack pointer
    sp: *mut u8,
}

impl Stack {
    fn new(size: usize) -> Stack {
        // Allocate with guard page
        let total = size + PAGE_SIZE;
        let ptr = mmap(total, PROT_READ | PROT_WRITE);

        // Mark guard page as inaccessible
        mprotect(ptr, PAGE_SIZE, PROT_NONE);

        Stack {
            guard: ptr,
            base: ptr.add(PAGE_SIZE),
            size,
            sp: ptr.add(total),
        }
    }

    fn grow(&mut self) {
        // Double the stack size
        let new_size = self.size * 2;
        if new_size > MAX_STACK_SIZE {
            panic!("Stack overflow");
        }
        // Reallocate and copy
        // ...
    }
}
```

---

## 11. Runtime Linking Requirements

### 11.1 Overview

Blood programs using concurrency features must link against the Blood runtime library. This section specifies the linking requirements for different platforms and build configurations.

### 11.2 Required Runtime Libraries

| Library | Description | Location |
|---------|-------------|----------|
| `libblood_runtime.a` | Static runtime library | `blood-runtime/target/release/` |
| `libblood_runtime.so` | Dynamic runtime library (Linux) | `blood-runtime/target/release/` |
| `libblood_runtime.dylib` | Dynamic runtime library (macOS) | `blood-runtime/target/release/` |
| `blood_runtime.dll` | Dynamic runtime library (Windows) | `blood-runtime/target/release/` |

### 11.3 Required Symbols

The following FFI symbols must be available at link time for concurrency features:

| Symbol | Purpose | Header |
|--------|---------|--------|
| `blood_scheduler_init` | Initialize the scheduler | `ffi_exports.rs` |
| `blood_scheduler_shutdown` | Clean shutdown | `ffi_exports.rs` |
| `blood_fiber_spawn` | Spawn a new fiber | `ffi_exports.rs` |
| `blood_fiber_yield` | Yield current fiber | `ffi_exports.rs` |
| `blood_fiber_await` | Wait for fiber completion | `ffi_exports.rs` |
| `blood_channel_create` | Create a channel | `ffi_exports.rs` |
| `blood_channel_send` | Send to channel | `ffi_exports.rs` |
| `blood_channel_recv` | Receive from channel | `ffi_exports.rs` |
| `blood_io_reactor_init` | Initialize I/O reactor | `ffi_exports.rs` |

### 11.4 Platform-Specific Linking

#### Linux

```bash
# Static linking (recommended for deployment)
clang program.o -L/path/to/blood-runtime/target/release \
    -lblood_runtime -lpthread -ldl -lm -o program

# Dynamic linking
clang program.o -L/path/to/blood-runtime/target/release \
    -Wl,-rpath,/path/to/blood-runtime/target/release \
    -lblood_runtime -lpthread -ldl -lm -o program

# With io_uring support (Linux 5.1+)
clang program.o -L/path/to/blood-runtime/target/release \
    -lblood_runtime -lpthread -ldl -lm -luring -o program
```

**Required system libraries**:
- `pthread` â€” Thread primitives
- `dl` â€” Dynamic loading (for FFI)
- `m` â€” Math library
- `uring` â€” io_uring support (optional, for async I/O)

#### macOS

```bash
# Static linking
clang program.o -L/path/to/blood-runtime/target/release \
    -lblood_runtime -lpthread -ldl -lm -framework CoreFoundation -o program

# Dynamic linking
clang program.o -L/path/to/blood-runtime/target/release \
    -Wl,-rpath,@executable_path/../lib \
    -lblood_runtime -lpthread -ldl -lm -framework CoreFoundation -o program
```

**Required frameworks**:
- `CoreFoundation` â€” System services
- `pthread` â€” Thread primitives

#### Windows

```cmd
REM Static linking
link program.obj /LIBPATH:C:\path\to\blood-runtime\target\release ^
    blood_runtime.lib ws2_32.lib userenv.lib bcrypt.lib ntdll.lib /OUT:program.exe

REM Dynamic linking
link program.obj /LIBPATH:C:\path\to\blood-runtime\target\release ^
    blood_runtime.dll.lib ws2_32.lib userenv.lib /OUT:program.exe
```

**Required system libraries**:
- `ws2_32.lib` â€” Windows Sockets (networking)
- `userenv.lib` â€” User environment
- `bcrypt.lib` â€” Cryptographic primitives
- `ntdll.lib` â€” NT system calls (for IOCP)

### 11.5 Build System Integration

#### Cargo (Rust projects using Blood)

```toml
[dependencies]
blood-runtime = { path = "../blood-runtime" }

[build-dependencies]
cc = "1.0"
```

#### CMake

```cmake
find_library(BLOOD_RUNTIME blood_runtime
    PATHS ${BLOOD_SDK}/lib
    REQUIRED)

target_link_libraries(my_program PRIVATE ${BLOOD_RUNTIME})

if(UNIX AND NOT APPLE)
    target_link_libraries(my_program PRIVATE pthread dl m)
elseif(APPLE)
    target_link_libraries(my_program PRIVATE pthread dl m
        "-framework CoreFoundation")
elseif(WIN32)
    target_link_libraries(my_program PRIVATE ws2_32 userenv bcrypt ntdll)
endif()
```

#### Blood Build Tool

The `blood build` command handles runtime linking automatically:

```bash
# Default: static linking
blood build program.blood -o program

# Explicit dynamic linking
blood build program.blood -o program --link-mode=dynamic

# Cross-compilation
blood build program.blood -o program --target=x86_64-unknown-linux-gnu
```

### 11.6 Runtime Initialization

Programs must initialize the runtime before using concurrency features:

```c
// C FFI initialization (generated by compiler)
int main(int argc, char** argv) {
    // Initialize runtime (scheduler, I/O reactor, etc.)
    blood_runtime_init(argc, argv);

    // Run the Blood main function
    int result = blood_main();

    // Clean shutdown
    blood_runtime_shutdown();

    return result;
}
```

The Blood compiler automatically generates this wrapper when compiling executables.

### 11.7 Minimal Runtime (Embedded)

For resource-constrained environments, a minimal runtime is available:

```bash
blood build program.blood -o program --runtime=minimal
```

Minimal runtime excludes:
- I/O reactor (no async I/O)
- Multi-worker scheduling (single-threaded)
- Debug symbols and tracing

**Minimal runtime size**: ~50 KB (stripped)

### 11.8 Verification

To verify runtime linking is correct:

```bash
# Linux: Check symbols
nm -u program | grep blood_

# macOS: Check symbols
nm -u program | grep blood_

# Windows: Check imports
dumpbin /imports program.exe | findstr blood_
```

All `blood_*` symbols should be resolved (not undefined).

---

## Appendix A: Scheduler Tuning

| Parameter | Default | Description |
|-----------|---------|-------------|
| `WORKERS` | CPU count | Worker threads |
| `INITIAL_STACK` | 8 KB | Initial fiber stack |
| `MAX_STACK` | 1 MB | Maximum fiber stack |
| `GLOBAL_QUEUE_SIZE` | 1024 | Global queue capacity |
| `LOCAL_QUEUE_SIZE` | 256 | Per-worker queue capacity |
| `STEAL_BATCH` | 32 | Fibers stolen at once |
| `PREEMPT_INTERVAL` | 10 ms | Preemption check interval |

---

## Appendix B: Debugging

```blood
// Fiber debugging
fn debug_fibers() / {Fiber, IO} {
    let stats = scheduler_stats();
    println("Active fibers: {}", stats.active);
    println("Suspended fibers: {}", stats.suspended);
    println("Total spawned: {}", stats.total_spawned);

    for fiber in all_fibers() {
        println("Fiber {}: {:?}", fiber.id, fiber.state);
        if let Some(name) = fiber.name {
            println("  Name: {}", name);
        }
        println("  Stack usage: {} bytes", fiber.stack_usage());
    }
}
```

---

## Appendix C: References

Concurrency model draws from:

- [Fiber (computer science) - Wikipedia](https://en.wikipedia.org/wiki/Fiber_(computer_science))
- [Naughty Dog's Fiber-Based Job System](https://www.gdcvault.com/play/1022186/Parallelizing-the-Naughty-Dog-Engine)
- [Tokio Scheduler Design](https://tokio.rs/blog/2019-10-scheduler)
- [Go Scheduler Design](https://morsmachine.dk/go-scheduler)
- [Project Loom (Java Virtual Threads)](https://openjdk.org/projects/loom/)

---

*This document is part of the Blood Language Specification.*
