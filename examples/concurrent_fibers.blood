// Concurrent Fibers in Blood
// ===========================
//
// This example demonstrates Blood's fiber-based concurrency model, which provides:
//
// - Lightweight Concurrency: Millions of concurrent fibers (stackful coroutines)
// - Cooperative Scheduling: Predictable yield points for deterministic behavior
// - Channel Communication: Type-safe message passing between fibers
// - Parallel Workloads: Efficient distribution across worker threads
//
// Blood's concurrency model uses M:N scheduling (M fibers to N OS threads) with
// work-stealing for load balancing. Fibers are the fundamental unit of concurrency,
// similar to Go's goroutines or Erlang's processes.
//
// See CONCURRENCY.md for the full specification.

// ===========================================================================
// Part 1: Effect Declarations for Concurrency
// ===========================================================================

// The Fiber effect provides core concurrency operations.
// Each operation is a "perform" that can suspend the current fiber.
effect Fiber {
    /// Spawn a new fiber to execute a task concurrently.
    /// Returns a handle that can be used to await the result.
    op spawn(task_id: i32) -> i32;

    /// Get the current fiber's identifier.
    op current() -> i32;

    /// Voluntarily yield control to the scheduler.
    /// Allows other fibers to run without blocking.
    op yield_fiber() -> ();

    /// Sleep for a specified duration (in milliseconds).
    op sleep(duration_ms: i32) -> ();
}

// The Channel effect provides typed message passing.
// Channels are the primary communication mechanism between fibers.
effect Channel<T> {
    /// Create a new bounded channel with specified capacity.
    /// Returns a channel identifier.
    op create(capacity: i32) -> i32;

    /// Send a value to a channel. Blocks if the channel is full.
    op send(channel_id: i32, value: T) -> ();

    /// Receive a value from a channel. Blocks if the channel is empty.
    op recv(channel_id: i32) -> T;

    /// Try to send without blocking. Returns true if successful.
    op try_send(channel_id: i32, value: T) -> bool;

    /// Try to receive without blocking. Returns value or -1 if empty.
    op try_recv(channel_id: i32) -> T;
}

// The FiberSync effect handles fiber synchronization.
effect FiberSync {
    /// Wait for a spawned fiber to complete and get its result.
    op await_fiber(fiber_id: i32) -> i32;

    /// Wait for multiple fibers, returning when all complete.
    op await_all(fiber_ids: i32) -> ();

    /// Wait for any of the fibers, returning the first to complete.
    op await_any(fiber_ids: i32) -> i32;
}

// The Cancel effect supports cooperative cancellation.
effect Cancel {
    /// Check if cancellation has been requested for current fiber.
    op is_cancelled() -> bool;

    /// Throw an error if cancellation was requested.
    /// This is a cancellation point where the fiber checks for cancellation.
    op check_cancelled() -> ();

    /// Request cancellation of a fiber.
    op cancel(fiber_id: i32) -> ();
}

// ===========================================================================
// Part 2: Fiber Creation Concepts
// ===========================================================================

// Struct representing work item for parallel processing
struct WorkItem {
    id: i32,
    value: i32,
}

// Struct representing computation result
struct ComputeResult {
    item_id: i32,
    result: i32,
    fiber_id: i32,
}

// Create a work item
fn work_item_new(id: i32, value: i32) -> WorkItem {
    WorkItem { id: id, value: value }
}

// Create a result
fn result_new(item_id: i32, result: i32, fiber_id: i32) -> ComputeResult {
    ComputeResult { item_id: item_id, result: result, fiber_id: fiber_id }
}

// Demonstrate fiber spawning concepts
fn demo_fiber_creation() {
    println_str("=== Part 2: Fiber Creation Concepts ===");
    println_str("");

    println_str("Fiber creation in Blood:");
    println_str("  1. Use 'perform Fiber.spawn(task_id)' to create a new fiber");
    println_str("  2. Each fiber gets its own stack (growable, starts at 8KB)");
    println_str("  3. Fibers are scheduled on worker threads (M:N model)");
    println_str("  4. Returns a fiber ID for later synchronization");
    println_str("");

    println_str("Fiber properties:");
    println_str("  - Initial stack: 8 KB (configurable)");
    println_str("  - Maximum stack: 1 MB (configurable)");
    println_str("  - Context switch: ~50-100 ns");
    println_str("  - Memory overhead: ~1-2 KB per suspended fiber");
    println_str("");

    // Simulate fiber creation workflow
    let work1: WorkItem = work_item_new(1, 100);
    let work2: WorkItem = work_item_new(2, 200);
    let work3: WorkItem = work_item_new(3, 300);

    println_str("Created 3 work items for parallel processing:");
    print_str("  Item 1: id=");
    print_int(work1.id);
    print_str(", value=");
    println_int(work1.value);
    print_str("  Item 2: id=");
    print_int(work2.id);
    print_str(", value=");
    println_int(work2.value);
    print_str("  Item 3: id=");
    print_int(work3.id);
    print_str(", value=");
    println_int(work3.value);
    println_str("");
}

// ===========================================================================
// Part 3: Cooperative Scheduling
// ===========================================================================

// Simulate a long-running computation that cooperatively yields
fn long_computation(iterations: i32) -> i32 {
    let mut sum: i32 = 0;
    let mut i: i32 = 0;

    while i < iterations {
        // Do some work
        sum = sum + (i * i);

        // Cooperative yield point: check every 100 iterations
        // In real Blood code: perform Fiber.yield_fiber()
        // This allows other fibers to run
        if i % 100 == 0 {
            // yield_fiber() would go here
            // This prevents any single fiber from monopolizing CPU
        }

        i = i + 1;
    }

    sum
}

// Demonstrate cooperative scheduling
fn demo_cooperative_scheduling() {
    println_str("=== Part 3: Cooperative Scheduling ===");
    println_str("");

    println_str("Blood uses cooperative scheduling with explicit yield points:");
    println_str("");
    println_str("Automatic yield points:");
    println_str("  - perform Fiber.yield_fiber()  : Explicit yield");
    println_str("  - perform FiberSync.await_fiber(id): Wait for fiber");
    println_str("  - channel.send() when full     : Block on channel");
    println_str("  - channel.recv() when empty    : Block on channel");
    println_str("  - perform Fiber.sleep(ms)      : Timer-based yield");
    println_str("");

    println_str("Preemption for safety:");
    println_str("  - Compiler inserts checks at function entry");
    println_str("  - Checks inserted at loop back-edges");
    println_str("  - Configurable preemption interval (~10ms default)");
    println_str("");

    // Demonstrate computation with yield points
    let result1: i32 = long_computation(50);
    let result2: i32 = long_computation(100);

    print_str("Computation result (50 iterations): ");
    println_int(result1);
    print_str("Computation result (100 iterations): ");
    println_int(result2);
    println_str("");

    println_str("Scheduling priorities:");
    println_str("  Priority::Low      = 0 : Background tasks");
    println_str("  Priority::Normal   = 1 : Default priority");
    println_str("  Priority::High     = 2 : Latency-sensitive");
    println_str("  Priority::Critical = 3 : System tasks");
    println_str("");
}

// ===========================================================================
// Part 4: Channel Communication
// ===========================================================================

// Struct representing a message in a channel
struct Message {
    sender_id: i32,
    content: i32,
    sequence: i32,
}

// Create a message
fn message_new(sender: i32, content: i32, seq: i32) -> Message {
    Message { sender_id: sender, content: content, sequence: seq }
}

// Simulate channel state
struct ChannelState {
    id: i32,
    capacity: i32,
    current_size: i32,
    closed: bool,
}

// Create channel state
fn channel_state_new(id: i32, capacity: i32) -> ChannelState {
    ChannelState {
        id: id,
        capacity: capacity,
        current_size: 0,
        closed: false,
    }
}

// Simulate sending to channel
fn channel_send(chan: ChannelState, msg: Message) -> ChannelState {
    // In real code: perform Channel.send(chan.id, msg)
    // This would block if channel is full
    ChannelState {
        id: chan.id,
        capacity: chan.capacity,
        current_size: chan.current_size + 1,
        closed: chan.closed,
    }
}

// Demonstrate channel communication patterns
fn demo_channel_communication() {
    println_str("=== Part 4: Channel Communication ===");
    println_str("");

    println_str("Channels are typed, bounded queues for fiber communication:");
    println_str("  - MPMC: Multi-producer, multi-consumer");
    println_str("  - Bounded: Backpressure when full");
    println_str("  - Type-safe: Values have concrete types");
    println_str("");

    // Simulate channel creation
    let chan: ChannelState = channel_state_new(1, 10);
    print_str("Created channel: id=");
    print_int(chan.id);
    print_str(", capacity=");
    println_int(chan.capacity);
    println_str("");

    // Create and send messages
    let msg1: Message = message_new(1, 100, 1);
    let msg2: Message = message_new(1, 200, 2);
    let msg3: Message = message_new(2, 300, 3);

    println_str("Messages to send:");
    print_str("  Message 1: sender=");
    print_int(msg1.sender_id);
    print_str(", content=");
    print_int(msg1.content);
    print_str(", seq=");
    println_int(msg1.sequence);
    print_str("  Message 2: sender=");
    print_int(msg2.sender_id);
    print_str(", content=");
    print_int(msg2.content);
    print_str(", seq=");
    println_int(msg2.sequence);
    print_str("  Message 3: sender=");
    print_int(msg3.sender_id);
    print_str(", content=");
    print_int(msg3.content);
    print_str(", seq=");
    println_int(msg3.sequence);
    println_str("");

    println_str("Channel patterns:");
    println_str("  1. Fan-out: One producer, multiple consumers");
    println_str("     - Work distribution pattern");
    println_str("     - Load balancing across workers");
    println_str("");
    println_str("  2. Fan-in: Multiple producers, one consumer");
    println_str("     - Result aggregation");
    println_str("     - Event collection");
    println_str("");
    println_str("  3. Pipeline: Chain of processing stages");
    println_str("     - Stage 1 -> Channel -> Stage 2 -> Channel -> Stage 3");
    println_str("     - Natural backpressure propagation");
    println_str("");
}

// ===========================================================================
// Part 5: Parallel Workload Patterns
// ===========================================================================

// Struct representing a worker in a worker pool
struct Worker {
    id: i32,
    tasks_completed: i32,
    total_work: i32,
}

// Create a worker
fn worker_new(id: i32) -> Worker {
    Worker { id: id, tasks_completed: 0, total_work: 0 }
}

// Simulate worker processing a task
fn worker_process(w: Worker, work_value: i32) -> Worker {
    // Simulate doing work
    let result: i32 = work_value * 2;

    Worker {
        id: w.id,
        tasks_completed: w.tasks_completed + 1,
        total_work: w.total_work + result,
    }
}

// Struct for parallel map result
struct ParMapResult {
    input: i32,
    output: i32,
}

// Demonstrate parallel workload distribution
fn demo_parallel_workloads() {
    println_str("=== Part 5: Parallel Workload Patterns ===");
    println_str("");

    println_str("Blood provides parallel primitives for common patterns:");
    println_str("");

    println_str("1. Parallel Map:");
    println_str("   data.par_map(|x| x * x)");
    println_str("   - Splits data into chunks");
    println_str("   - Spawns fiber per chunk");
    println_str("   - Collects results");
    println_str("");

    // Simulate parallel map
    let mut i: i32 = 1;
    let mut sum: i32 = 0;
    println_str("   Simulated parallel map: square of 1..5");
    while i <= 5 {
        let squared: i32 = i * i;
        print_str("     ");
        print_int(i);
        print_str(" -> ");
        println_int(squared);
        sum = sum + squared;
        i = i + 1;
    }
    print_str("   Sum of squares: ");
    println_int(sum);
    println_str("");

    println_str("2. Parallel Reduce:");
    println_str("   data.par_reduce(0, |a, b| a + b)");
    println_str("   - Divide-and-conquer reduction");
    println_str("   - Tree-shaped aggregation");
    println_str("   - Preserves associativity");
    println_str("");

    println_str("3. Worker Pool:");
    println_str("   - Fixed number of worker fibers");
    println_str("   - Tasks distributed via channel");
    println_str("   - Workers pull tasks as available");
    println_str("");

    // Simulate worker pool
    let mut w1: Worker = worker_new(1);
    let mut w2: Worker = worker_new(2);
    let mut w3: Worker = worker_new(3);

    // Simulate work distribution
    w1 = worker_process(w1, 10);
    w2 = worker_process(w2, 20);
    w3 = worker_process(w3, 30);
    w1 = worker_process(w1, 40);
    w2 = worker_process(w2, 50);

    println_str("   Worker pool simulation (3 workers, 5 tasks):");
    print_str("     Worker 1: tasks=");
    print_int(w1.tasks_completed);
    print_str(", total_work=");
    println_int(w1.total_work);
    print_str("     Worker 2: tasks=");
    print_int(w2.tasks_completed);
    print_str(", total_work=");
    println_int(w2.total_work);
    print_str("     Worker 3: tasks=");
    print_int(w3.tasks_completed);
    print_str(", total_work=");
    println_int(w3.total_work);
    println_str("");
}

// ===========================================================================
// Part 6: Structured Concurrency
// ===========================================================================

// Struct representing a nursery (structured concurrency scope)
struct Nursery {
    id: i32,
    active_fibers: i32,
    completed_fibers: i32,
}

// Create a nursery
fn nursery_new(id: i32) -> Nursery {
    Nursery { id: id, active_fibers: 0, completed_fibers: 0 }
}

// Spawn in nursery
fn nursery_spawn(n: Nursery) -> Nursery {
    Nursery {
        id: n.id,
        active_fibers: n.active_fibers + 1,
        completed_fibers: n.completed_fibers,
    }
}

// Complete fiber in nursery
fn nursery_complete(n: Nursery) -> Nursery {
    Nursery {
        id: n.id,
        active_fibers: n.active_fibers - 1,
        completed_fibers: n.completed_fibers + 1,
    }
}

// Demonstrate structured concurrency
fn demo_structured_concurrency() {
    println_str("=== Part 6: Structured Concurrency ===");
    println_str("");

    println_str("Blood enforces structured concurrency:");
    println_str("  - Child fibers MUST complete before parent");
    println_str("  - No orphaned fibers");
    println_str("  - Automatic cleanup on scope exit");
    println_str("");

    println_str("Nursery pattern:");
    println_str("  nursery(|scope| {");
    println_str("      scope.spawn(|| task1());");
    println_str("      scope.spawn(|| task2());");
    println_str("      scope.spawn(|| task3());");
    println_str("      // All tasks guaranteed complete here");
    println_str("  })");
    println_str("");

    // Simulate nursery lifecycle
    let mut n: Nursery = nursery_new(1);
    println_str("Nursery lifecycle simulation:");

    print_str("  Created nursery: id=");
    println_int(n.id);

    n = nursery_spawn(n);
    n = nursery_spawn(n);
    n = nursery_spawn(n);
    print_str("  After 3 spawns: active=");
    println_int(n.active_fibers);

    n = nursery_complete(n);
    n = nursery_complete(n);
    print_str("  After 2 complete: active=");
    print_int(n.active_fibers);
    print_str(", completed=");
    println_int(n.completed_fibers);

    n = nursery_complete(n);
    print_str("  After all complete: active=");
    print_int(n.active_fibers);
    print_str(", completed=");
    println_int(n.completed_fibers);
    println_str("  -> Nursery can now exit safely");
    println_str("");

    println_str("Benefits of structured concurrency:");
    println_str("  1. No resource leaks from orphaned fibers");
    println_str("  2. Errors propagate to parent scope");
    println_str("  3. Cancellation cascades to children");
    println_str("  4. Easy to reason about fiber lifetimes");
    println_str("");
}

// ===========================================================================
// Part 7: Cancellation and Error Handling
// ===========================================================================

// Struct representing cancellable task state
struct CancellableTask {
    id: i32,
    progress: i32,
    is_cancelled: bool,
    completed: bool,
}

// Create cancellable task
fn cancellable_task_new(id: i32) -> CancellableTask {
    CancellableTask {
        id: id,
        progress: 0,
        is_cancelled: false,
        completed: false,
    }
}

// Advance task with cancellation check
fn task_step(t: CancellableTask) -> CancellableTask {
    if t.is_cancelled {
        // Would perform Cancel.check_cancelled() in real code
        t
    } else if t.progress >= 100 {
        CancellableTask {
            id: t.id,
            progress: t.progress,
            is_cancelled: t.is_cancelled,
            completed: true,
        }
    } else {
        CancellableTask {
            id: t.id,
            progress: t.progress + 10,
            is_cancelled: t.is_cancelled,
            completed: false,
        }
    }
}

// Cancel a task
fn task_cancel(t: CancellableTask) -> CancellableTask {
    CancellableTask {
        id: t.id,
        progress: t.progress,
        is_cancelled: true,
        completed: false,
    }
}

// Demonstrate cancellation
fn demo_cancellation() {
    println_str("=== Part 7: Cancellation and Error Handling ===");
    println_str("");

    println_str("Blood supports cooperative cancellation:");
    println_str("  - Cancellation is requested, not forced");
    println_str("  - Fibers check at cancellation points");
    println_str("  - Cleanup code can run before exit");
    println_str("");

    println_str("Cancellation pattern:");
    println_str("  fn cancellable_work() / {Cancel} {");
    println_str("      for item in items {");
    println_str("          check_cancelled();  // Cancellation point");
    println_str("          process(item);");
    println_str("      }");
    println_str("  }");
    println_str("");

    // Simulate task with cancellation
    let mut task: CancellableTask = cancellable_task_new(1);
    println_str("Task cancellation simulation:");

    print_str("  Created task: id=");
    println_int(task.id);

    task = task_step(task);
    task = task_step(task);
    task = task_step(task);
    print_str("  After 3 steps: progress=");
    println_int(task.progress);

    // Simulate cancellation request
    task = task_cancel(task);
    println_str("  Cancellation requested");

    task = task_step(task);
    print_str("  After step (cancelled): progress=");
    print_int(task.progress);
    print_str(", is_cancelled=");
    if task.is_cancelled { println_str("true"); } else { println_str("false"); }

    println_str("");
    println_str("Error handling across fibers:");
    println_str("  - Errors in child fibers propagate to parent");
    println_str("  - Nursery waits for all children even on error");
    println_str("  - First error wins (others cancelled)");
    println_str("");
}

// ===========================================================================
// Part 8: Synchronization Primitives
// ===========================================================================

// Struct representing mutex state
struct MutexState {
    id: i32,
    locked: bool,
    waiters: i32,
}

// Create mutex
fn mutex_new(id: i32) -> MutexState {
    MutexState { id: id, locked: false, waiters: 0 }
}

// Acquire mutex
fn mutex_acquire(m: MutexState) -> MutexState {
    if m.locked {
        // Would suspend fiber in real code
        MutexState {
            id: m.id,
            locked: true,
            waiters: m.waiters + 1,
        }
    } else {
        MutexState {
            id: m.id,
            locked: true,
            waiters: m.waiters,
        }
    }
}

// Release mutex
fn mutex_release(m: MutexState) -> MutexState {
    MutexState {
        id: m.id,
        locked: false,
        waiters: m.waiters,
    }
}

// Struct representing barrier state
struct BarrierState {
    count: i32,
    waiting: i32,
    generation: i32,
}

// Create barrier
fn barrier_new(count: i32) -> BarrierState {
    BarrierState { count: count, waiting: 0, generation: 0 }
}

// Wait at barrier
fn barrier_wait(b: BarrierState) -> BarrierState {
    let arrived: i32 = b.waiting + 1;
    if arrived == b.count {
        // All arrived, release
        BarrierState {
            count: b.count,
            waiting: 0,
            generation: b.generation + 1,
        }
    } else {
        BarrierState {
            count: b.count,
            waiting: arrived,
            generation: b.generation,
        }
    }
}

// Demonstrate synchronization primitives
fn demo_synchronization() {
    println_str("=== Part 8: Synchronization Primitives ===");
    println_str("");

    println_str("Blood provides synchronization primitives:");
    println_str("");

    println_str("1. Mutex<T> - Mutual exclusion");
    let mut mtx: MutexState = mutex_new(1);
    mtx = mutex_acquire(mtx);
    print_str("   Acquired mutex: locked=");
    if mtx.locked { println_str("true"); } else { println_str("false"); }
    mtx = mutex_release(mtx);
    print_str("   Released mutex: locked=");
    if mtx.locked { println_str("true"); } else { println_str("false"); }
    println_str("");

    println_str("2. RwLock<T> - Reader-writer lock");
    println_str("   - Multiple readers OR one writer");
    println_str("   - Writer-preferring to prevent starvation");
    println_str("");

    println_str("3. Barrier - Synchronization point");
    let mut barrier: BarrierState = barrier_new(3);
    println_str("   Created barrier for 3 fibers");
    barrier = barrier_wait(barrier);
    print_str("   Fiber 1 arrived: waiting=");
    println_int(barrier.waiting);
    barrier = barrier_wait(barrier);
    print_str("   Fiber 2 arrived: waiting=");
    println_int(barrier.waiting);
    barrier = barrier_wait(barrier);
    print_str("   Fiber 3 arrived: waiting=");
    print_int(barrier.waiting);
    print_str(" (released, gen=");
    print_int(barrier.generation);
    println_str(")");
    println_str("");

    println_str("4. Semaphore - Counting permits");
    println_str("   - Acquire decrements, blocks at 0");
    println_str("   - Release increments, wakes waiter");
    println_str("");

    println_str("5. Once - One-time initialization");
    println_str("   - First caller runs initializer");
    println_str("   - Others wait then see result");
    println_str("");
}

// ===========================================================================
// Part 9: Effect Handler Integration
// ===========================================================================

// Handler for fiber runtime simulation
deep handler FiberRuntime for Fiber {
    let mut fiber_count: i32
    let mut current_id: i32

    return(x) { x }

    op spawn(task_id) {
        fiber_count = fiber_count + 1;
        resume(fiber_count)
    }

    op current() {
        resume(current_id)
    }

    op yield_fiber() {
        // In real implementation: save state and switch fibers
        resume(())
    }

    op sleep(duration_ms) {
        // In real implementation: register timer and suspend
        resume(())
    }
}

// Handler for channel simulation
// This mock handler stores the last sent value and returns it on recv.
// In a real implementation, channels would have proper buffers.
deep handler ChannelRuntime<T> for Channel<T> {
    let mut next_channel: i32
    let mut last_sent: T

    return(x) { x }

    op create(capacity) {
        next_channel = next_channel + 1;
        resume(next_channel)
    }

    op send(channel_id, value) {
        // Store the value for later recv
        last_sent = value;
        resume(())
    }

    op recv(channel_id) {
        // Return the last sent value (mock loopback behavior)
        resume(last_sent)
    }

    op try_send(channel_id, value) {
        last_sent = value;
        resume(true)
    }

    op try_recv(channel_id) {
        resume(last_sent)
    }
}

// Demonstrate effect handler integration
fn demo_effect_handlers() {
    println_str("=== Part 9: Effect Handler Integration ===");
    println_str("");

    println_str("Concurrency operations are effects in Blood:");
    println_str("  - Fiber.spawn, Fiber.yield are effect operations");
    println_str("  - Channel.send, Channel.recv are effect operations");
    println_str("  - Handlers implement the runtime behavior");
    println_str("");

    println_str("Runtime handler example:");
    println_str("  deep handler FiberRuntime for Fiber {");
    println_str("      op spawn(task_id) {");
    println_str("          let fid = scheduler.spawn(task_id);");
    println_str("          resume(fid)");
    println_str("      }");
    println_str("      op yield_fiber() {");
    println_str("          scheduler.yield_current();");
    println_str("          resume(())");
    println_str("      }");
    println_str("  }");
    println_str("");

    println_str("Running concurrent code:");
    println_str("  fn run<T>(f: fn() -> T / {Fiber}) -> T {");
    println_str("      with FiberRuntime { ... } handle {");
    println_str("          f()");
    println_str("      }");
    println_str("  }");
    println_str("");

    println_str("Effect rows track concurrency requirements:");
    println_str("  fn producer() / {Fiber, Channel<i32>} { ... }");
    println_str("  fn consumer() / {Fiber, Channel<i32>} { ... }");
    println_str("  fn pipeline() / {Fiber} {");
    println_str("      with ChannelRuntime { ... } handle {");
    println_str("          // producer and consumer can use channels");
    println_str("      }");
    println_str("  }");
    println_str("");
}

// ===========================================================================
// Part 10: Memory Safety with Fibers
// ===========================================================================

// Demonstrate memory safety concepts
fn demo_memory_safety() {
    println_str("=== Part 10: Memory Safety with Fibers ===");
    println_str("");

    println_str("Blood prevents data races by construction:");
    println_str("");

    println_str("1. Fiber-local regions cannot be shared:");
    println_str("   region local_data {");
    println_str("       let buffer = allocate();");
    println_str("       // ERROR: spawn(|| use(&buffer))");
    println_str("       // Compile error: buffer escapes fiber");
    println_str("   }");
    println_str("");

    println_str("2. Sharing requires explicit promotion to Tier 3:");
    println_str("   let shared = persist(data.clone());");
    println_str("   spawn(|| use(&shared));  // OK: Tier 3 is shareable");
    println_str("");

    println_str("3. Channels transfer ownership:");
    println_str("   channel.send(data);");
    println_str("   // data is now owned by receiver");
    println_str("   // No aliasing across fiber boundary");
    println_str("");

    println_str("4. Synchronized<T> for shared mutable state:");
    println_str("   let counter = Synchronized::new(0);");
    println_str("   spawn(|| counter.lock().increment());");
    println_str("   spawn(|| counter.lock().increment());");
    println_str("");

    println_str("Generation snapshots across fiber suspension:");
    println_str("  - When fiber suspends, its references are snapshotted");
    println_str("  - Resume validates no references became stale");
    println_str("  - Prevents use-after-free across yield points");
    println_str("");
}

// ===========================================================================
// Main Entry Point
// ===========================================================================

fn main() {
    println_str("================================================================");
    println_str("     Blood Concurrent Fibers Demonstration");
    println_str("     Lightweight Concurrency with Effect Handlers");
    println_str("================================================================");
    println_str("");

    demo_fiber_creation();
    demo_cooperative_scheduling();
    demo_channel_communication();
    demo_parallel_workloads();
    demo_structured_concurrency();
    demo_cancellation();
    demo_synchronization();
    demo_effect_handlers();
    demo_memory_safety();

    println_str("================================================================");
    println_str("     Key Concurrency Concepts");
    println_str("================================================================");
    println_str("");
    println_str("1. Fibers are lightweight (8KB stack, ~50ns context switch)");
    println_str("2. Cooperative scheduling with explicit yield points");
    println_str("3. Channels provide safe communication between fibers");
    println_str("4. Structured concurrency ensures no orphaned fibers");
    println_str("5. Cancellation is cooperative (check_cancelled points)");
    println_str("6. Concurrency operations are effects with handlers");
    println_str("7. Memory safety enforced across fiber boundaries");
    println_str("");
    println_str("================================================================");
    println_str("     Demonstration Complete");
    println_str("================================================================");
}
